REPORT OF THE INTERNATIONAL BIOETHICS COMMITTEE OF UNESCO (IBC) ON THE ETHICAL ISSUES OF NEUROTECHNOLOGY
I.	INTRODUCTION
1.	Brain activity is the basis of cognitive, affective or other brain states. Brain activity is so important to our life that, in many countries, death is legally defined by irreversible cessation of brain activity. Brain activity provides information inherent to all human beings regardless of gender, nationality, language, or religion. The centrality of the brain activity to notions of human identity, freedom of thought, autonomy, privacy, and human flourishing makes of paramount importance ethical, legal, and societal impact of recording (‘reading’) and/or modulating (‘writing’) brain activity through various devices and procedures collectively named neurotechnology . This report has been undertaken considering the rapid development of the field and the IBC’s mission to promote reflection on the ethical and legal issues raised by research in the life sciences and their applications.
2.	Throughout history, physicians have attempted to understand and treat diseases of the brain using various methods, beginning with trepanning or trephining in ancient times. There is evidence to show that this practice existed in ancient Egypt, Greece, Rome, West Asia and China, and this method was being used in many continents as late as the 18th century (Kandel et al., 2000). Neurological conditions such as epilepsy, migraine, brain tumours and encephalitis, and mental conditions such as depression and bipolar disorders, for which there were no apparent causes, were often attributed to divine punishment or demonic possession. 
3.	Advances in the understanding of anatomy and physiology helped by microscopy and histology during the 18th century, led to the establishment of neurology as a major branch of medicine in the 19th century. The anatomo-pathological method initiated by Laennec  allowed to link clinical findings to post-mortem changes, and thus defined several neurological conditions. The discovery of neurotransmitters and their actions on the brain and peripheral nerves was initiated in 1878 when Claude Bernard described the nerve/muscle blocking action of curare. The next century saw the remarkable understanding of the chemical action in the brain and the receptor transmitter/inhibitor set-up, led to the development of valuable drugs to combat a wide variety of neurological diseases, including the hitherto untreatable psychiatric disorders.
4.	Even if nerves electrical properties related to action potentials and nerve impulse transmission at synapses were already reported by Luigi Galvani, Guillaume Duchenne de Boulogne, Hermann Von Helmholtz or Charles Sherrington to name just a few, birth of neurotechnology may be dated with the demonstration by Hans Berger in 1929 that it was possible to record changes of electrical potential in the human brain with electroencephalography device that led to important advances such as the accurate diagnosis and treatment of epilepsies.
5.	The chance discovery of X-rays by the physicist Wilhelm Rontgen in 1895 provided the first non-invasive internal view of the human body. More advanced, refined and safer imaging techniques would be introduced in the latter part of the 20th century - ultrasound scan (1956), computerized axial tomography (1967) and magnetic resonance imaging (1980). These and newer technologies used to access, investigate and monitor brain structure and function would present certain ethical concerns, not seen with the use of neuropharmacological drugs. 
6.	Neurotechnology is the field of devices and procedures used to access, monitor, investigate, assess, manipulate, and/or emulate the structure and function of the neural systems of animals or human beings. These include: (i) technical and computational tools that measure and analyse chemical and electrical signals in the nervous system, be it the brain or nerves in the limbs. These may be used to identify the properties of nervous system activity, understand how the brain works, diagnose pathological conditions, or control external devices (neuro-prosthesis, ‘brain machine interfaces’); and (ii) technical tools that interact with the nervous system to change its activity, for example to restore sensory input such as with cochlear implants to restore hearing or deep brain stimulation to stop tremor and treat other pathological conditions. They are meant to either record signals from the brain and ‘translate’ them into technical control commands, or to manipulate brain activity by applying electrical or optical stimuli.
7.	Neurotechnology may be restricted to direct recording of the human brain activity and/or direct influence/modification of brain activity but can also be seen on a larger scale as any device and/or application (apps, AI, big data, etc.) able to derive knowledge on an individual’s brain activity and/or influence/modify an individual’s brain activity. As such, neurotechnology is any technology that has a fundamental influence on how people understand the brain and various aspects of consciousness, thought, and higher order activities in the brain. It also includes technologies that are designed to improve and repair brain function and allow researchers and clinicians to visualize brain structure and function.
8.	The present report will consider neurotechnology through health applications, as well as direct-to-consumer (DTC) neurotechnology (such as neurogaming, well-being devices, etc.), drivers safety applications, education and any other field of application. 
9.	Brain disorders represent a major and growing burden worldwide: one third of health expenses in developed countries (DiLuca and Olesen, 2014) and a growing burden in LMICs (Feigin et al., 2020). Brain disorders include neurological and mental disorders, some of the later often called mental and psychosocial disabilities or mental impairment by patient organizations and by the United Nation Department of Economics and Social affairs . Consequently, there is a need to provide new treatments and deliver better preventive and therapeutic solutions to millions of people suffering from neurological and mental illness. To this end, enhancing our scientific understanding of human brain function and unlocking the pathological conundrums of several treatment-resistant neurological and mental disorders is a major priority.
10.	Investment in brain research has become extremely important, with a growing number of large-scale programs aimed at developing technologies to intervene on the brain (IBI, 2016). In 2013, the United States launched the Brain Initiative whereas the European Union launched the Human Brain Project. Japan, Korea, Australia, China and Canada also developed large programs on ‘cracking the brain’s code’, both to better understand its structure and mental processes, and to develop new technologies to, among other things, control robots, autonomous systems, hybrid technologies, in order to treat certain pathologies and to compensate for forms of disability.
11.	‘Neural data’ (also called ‘brain data’ ) are becoming a sought-after data type and commodity beyond the medical sector (in particular, the consumer market). Consumer neurotechnology, digital phenotyping , affective computing , neurogaming  and neuromarketing  are some of the domains where this commodity is highly valued. This increasing extra-medical availability of brain data raises a challenge for ethics and for human rights, and obviously requires governance. Risks include re-identification, hacking, unauthorized reuse, asymmetric commodification, privacy-sensitive data mining, digital surveillance, trading-rights-for-services, co-optation for non-benign purposes and other misuses. 
12.	At the time of the present report there are few regulations on neurotechnology outside of regulation on medical devices used in the medical field or in the field of scientific research even though some countries actually develop new legal instruments , . Of note, the Organization for Economic Cooperation and Development (OECD) Council adopted on 11 December 2019, the OECD Recommendation on Responsible Innovation in Neurotechnology, aiming to guide governments and innovators to anticipate and address the ethical, legal and social challenges raised by novel neurotechnologies while promoting innovation in the field (OECD, 2019) that presently remain non-binding principles. 
13.	As these technologies can be used to improve the cognitive, sensory and motor capacities of some patients with neurological disorders, this opens doors for similar technologies to be used by neurologically-healthy individuals for enhancement purposes. Human enhancement refers to a very broad range of techniques and approaches aimed at augmenting body or cognitive functions, that result in potentially improved characteristics and capabilities, sometimes beyond the existing human range. Augmentation technology should not only enhance the well-being and quality of life of an individual but also have positive effects on the community and society.
14.	Neurotechnology was developed and used for health-related purposes, but it is increasingly applied in contexts outside the healthcare domain. For instance, the industry is incorporating neuroscience in the conception of marketing tools, while the fields of teaching, gaming, and entertainment have also seen a growing interest in using neurotechnology to influence the brain in many ways. In these fields, specific attention must be given to children and adolescents, due to the particularly plastic state of the developing human brain.
15.	Neurotechnology sits at the convergence of neuroscience, engineering, data science, information and communication technology and artificial intelligence. Brain-related measurements can be combined with other digitally available information such as online searches, social media, self-tracked data and geolocation – sometimes referred to as ‘digital exhaust’. Advances in big data analytics and machine learning might enable a greater inferential capacity to identify patterns and predict outcomes based on the combination of different data sources (see Report of the IBC on Consent (UNESCO, 2008) and Report of the IBC on Big Data and Health (UNESCO, 2017a)).
16.	The Universal Declaration on Bioethics and Human Rights (UNESCO, 2005) offers a general framework to analyse the legal and ethical aspects and implications of neurotechnology, specially Articles 2 (Aims); 3 (Human dignity and human rights); 4 (Benefit and harm); 5 (Autonomy and individual responsibility); 6 (Consent); 8 (Respect for human vulnerability and personal integrity); 9 (Privacy and confidentiality); 10 (Equality, justice and equity); 11 (Non-discrimination and non-stigmatization) and 13 (Solidarity and cooperation).
17.	This report will investigate the intersection between neurotechnology, ethics and human rights, and envisage for the adaptive interpretation of human rights in light of emerging technologies applied to human brain activities. More precisely, the scope of the report will embrace the numerous ethical and legal issues raised by “reading and/or writing” the brain activity to ask if the questions are so important and so novel that we consequently need a novel set of neuro-specific human rights such as the right to cognitive liberty, the right to mental privacy, the right to mental integrity, and the right to psychological continuity or if these rights challenged by neurotechnology are already enshrined in existing human rights, but need to be more explicitly respected through precisely written guarantees. For the purpose of this report, neurorights are defined as human rights-based “ethical, legal, social, or natural principles of freedom or entitlement related to a person’s cerebral and mental domain; that is, the fundamental normative rules for the protection and preservation of the human brain and mind.” (Ienca, 2021b).
II.	SHORT OVERVIEW OF EXISTING NEUROTECHNOLOGY
II.1.	Neuroimaging
18.	Neuroimaging or brain imaging are the techniques to either directly or indirectly access the structure and function (reflected by electrical activity, oxygen and/or energy consumption, neurotransmitter release…) of the central nervous system. These technics are said “non-invasive” if they don’t need to open the skull to directly access the brain. They are said “invasive” otherwise. We can cite here a few of the most common non-invasive techniques used today. They differ in terms of their spatial and temporal resolution. The most popular and accessible neuroimaging technique is electroencephalography (EEG) a method of brain exploration that measures the electrical activity of the brain using electrodes placed over the surface of the scalp. High density EEG (hdEEG) combines the superior temporal resolution of EEG recordings with increased spatial resolution. Computed tomography scan uses computer-processed combinations of many X-rays measurements taken from different angles to produce cross-sectional images (virtual ‘slices’) of the brain. Magnetic resonance imaging (MRI) produces pictures of the anatomy of the brain using strong magnetic fields. Magnetoencephalography (MEG) is used for mapping brain activity by recording small magnetic fields produced by the electric activity of the brain. Positron emission tomography (PET) is an imaging technique that uses radioactive substances injected intravenously to visualize and measure metabolism of given brain regions. Cranial ultrasound is a technique for scanning the brain using high-frequency sound waves. It is used almost exclusively in babies because their fontanelle provides an ‘acoustic window’. Functional near-infrared spectroscopy (fNIRS) is capable of visualizing changes both in oxy- and deoxyhemoglobin concentration and is a rapidly developing non-invasive technique to evaluate changes in cerebral blood flow to given regions of the cerebral cortex. Of note, people wearing (mobile) fNIRS can move around in a relatively unconstrained way due to its robustness to movement artefacts allowing to record their brain activity in real life conditions – nothing like MRI, MEG, PET or EEG in that regard.
19.	Functional magnetic resonance imaging (fMRI) is a non-invasive method for studying the functional anatomy of the human brain. fMRI raises major ethical questions throughout the research process: “from the conceptualization of experiments through their design, conduct, and analysis, to the interpretation and dissemination of results, and the possible implications and applications of research - informed consent - the investigation of incidental findings, the potential impact of neurological conditions on cognition and selfhood; also how brain images should be communicated: fMRI scans are highly processed representations of an indirect measure of neural activity, but are often described as if they are direct snapshots of the mind in action” (Garnett et al., 2011).
II.2.	Neurodevices
20.	Neurotechnology and neurodevices can replace parts of the body (e.g., robotic prostheses), stimulate or inhibit functions of the brain (e.g., implanted deep brain stimulators), in order to improve people's health and well-being. Deep brain stimulation (DBS) involves implanting electrodes within certain areas of the brain. These electrodes produce electrical impulses that regulate abnormal impulses or affect certain cells and chemicals within the brain. The amount of stimulation in deep brain stimulation is controlled by a pacemaker-like device placed under the skin in the upper chest. A wire that travels under the skin connects this device to the electrodes in the brain. The fine tuning of the pacemaker is done in the hospital and its activation remains under the control of the patient. Work-in-progress evaluates integration of algorithms to adapt the stimulation to patient’s activity and/or remote access through wireless devices. 
21.	Deep brain stimulation is approved to treat a number of conditions, such as Parkinson's disease, essential tremor, dystonia, epilepsy, obsessive-compulsive disorder. Deep brain stimulation is also being studied as a potential treatment for major depression (major), Traumatic brain injury, Stroke recovery, addiction, chronic pain, cluster headache, dementia, Tourette syndrome, Huntington's disease, multiple sclerosis.
22.	Possible side effects of DBS are frequently underestimated. Complications of DBS fall into three categories: surgery complications, hardware (device and wires) complications, and stimulation-related complications. Manic psychosis, hypersexuality, pathological gambling and mood swings are associated with dopaminergic treatments of some advanced Parkinson disease and their worsening by DBS have been reported. 
23.	Transcranial direct current stimulation (tDCS) or other Transcranial electrical stimulation (tES) are devices delivering continuous currents supposedly to enhance concentration or relaxation. We observe the development of Do-it-yourself (DIY) neurotechnology with self-assembled devices for personal use by non-professionals to alter their brain functions. 
II.3.	Brain computer interface 
24.	Brain Computer Interfaces (BCIs) are a type of neurotechnology that aims to translate brain processes that underlie thought and action into desired outcomes (e.g. increasing mood in a depressed person or moving a prosthetic limb). This is possible by collecting the data related to neural activity by sensors or electrodes placed in the brain, on the brain, or over the surface of the scalp, transforming them into a signal and then converting this signal into a mechanical or electrical action. BCIs are often directed at researching, mapping, assisting, augmenting, or repairing human cognitive or sensory-motor function (for example, in the case of a brain lesion resulting in hemiplegia, paraplegia or tetraplegia). They can be invasive, partially invasive or non-invasive.  Invasive BCI requires surgery to implant electrodes within the grey matter of the brain, for directly relaying brain signals to device output, as in the case of treatments for non-congenital blindness.
25.	BCIs focusing on motor neuroprosthetics aim to either restore movement in individuals with paralysis or provide devices to assist them to communicate or physically interact with their environment, such as interfaces with computers or robot arms. Partially invasive BCI devices are implanted inside the skull but rest outside the brain, such as Ecocorticography (EcoG) technology. Noninvasive EEG-based technologies and interfaces have been used for a much broader variety of applications. Neuroprosthetics is an area of neuroscience concerned with neural prostheses, that uses artificial devices to replace the function of impaired nervous systems and brain-related problems, or to replace the sensory organs themselves. The first neuroprosthetic device was the pacemaker. 
26.	BCI focusing on sensory prosthetics aim to restore the brain perception of sensory organs, such as eyes for sight or ears for earing. While these devices are restoring sensory capabilities for millions, some people raised the question of neurotypism in comparison with neurodiversity. Cochlear implants are an example of a device that has received strong ethical challenges from the deaf community (Hyde and Power, 2006).
27.	Deep learning, partly modelled on biological processes occurring within the human brain, enables machines to recognize shapes and patterns. Brain Computer Interfaces use deep learning to decode brain activity and some can help paralyzed patients to regain speech or movement. The same kind of algorithms can be used to operate autonomous weapons systems (Drew, 2019). Deep learning can also be also applied for medical tasks, with prominent examples being convolutional neural networks (ConvNets) on EEG signal (Schirrmeister, 2017).
II.4.	Artificial Intelligence in neurosciences
28.	Artificial Intelligence (AI) is a broad term that refers to the activity devoted to make machines ‘intelligent’, such as what is required for computer vision or ‘autonomous’ robots. While there is no single agreed-upon definition of AI, it is widely agreed that machines based on or which incorporate AI are potentially capable of imitating or even exceeding some human cognitive capacities, including sensing, language interaction, reasoning and analysis, problem solving, and even creativity (Miraux, 2018). UNESCO’s Recommendation on the Ethics of AI adopted by 193 Member States of UNESCO in November 2021 approaches “AI systems as systems which have the capacity to process data and information in a way that resembles intelligent behaviour,  and  typically  includes  aspects  of  reasoning,  learning,  perception,  prediction,  planning or control.” To be able to perform such tasks, a device embedded with AI needs to be able to sense the environment and to collect data dynamically, to process it promptly and to respond – based on its past ‘experience’, its pre-set principles for decision-making and its anticipation about the future. The ability to efficiently integrate dynamic data acquisition and machine-learning algorithms for prompt decision-making enables the creation of ‘cognitive machines’. Cognitive machines are strictly linked to neuroscience and neurotechnology.
29.	The history of Artificial Intelligence is intertwined with the history of neuroscience itself. Pioneering scientists in AI (many of them originally from neuroscience) turned to the human brain as for guidance for the development of intelligent machines (LeCun et al., 2015), and also borrowed most of the vocabulary from neurology and psychology, like artificial neural networks (although the neurons in question in AI are mathematical functions, not biological organisms).
30.	This type of artificial intelligence does not rely on expert systems (a corpus of knowledge), but on large-scale statistical processing of information through an iterative learning process (Levy, 2018). With the ability to rapidly identify patterns in large, complex data sets, AI has seen promising results in the past decade, in part by emulating how the brain performs certain computations. Contemporary cognitive science can benefit from the power of AI, both as a model for developing and testing ideas about how the brain performs computations, and as a tool for processing the complex data sets that researchers are producing (Savage, 2019).
31.	The convergence in AI, microsystems engineering and big data methods, make intelligent neurotechnological systems and AI-based algorithms for computational neuroscience one of the fastest growing fields of neuromedical research and innovation. These developments offer new possibilities for improving the understanding of brain disorders, identifying new biomarkers, building intelligent decision-support systems, and many other beneficial applications, but also create important ethical, legal, philosophical, social and political challenges.
32.	AI algorithms in clinical neuroscience research are used for predictive and diagnostic purposes, i.e. machine learning algorithms to detect early signs of Alzheimer’s disease and mental disabilities from patterns of activity or structural anomalies in brain scans. There are many ethical issues related: automatic diagnoses changing the model of patient doctor relationships, algorithm discrimination, incidental findings and privacy concerns, transparency and bias, among others.
III.	NEUROTECHNOLOGY AND ETHICS
III.1.	Neurotechnology and ethical principles 
33.	‘Neuroethics’  (Figueroa, 2016; Dubljević, 2017) deals with the issues and study of ethical questions that emerge from scientific discoveries and technological applications in or on the brain. Neuroethics includes, on the one hand, the ethics of neuroscience, which is a moral framework for guiding research in the field of neuroscience and the technological application of its results in humans, and on the other hand the neuroscience of ethics, which aims to investigate the neurological basis of morality. In the framework of this report, the focus will be on the ethics of neuroscience, which is mainly at stakes (despite there are implicit consequences for the neuroscience of ethics).
34.	Currently, the use of neurotechnologies and their implications on the brain have a high level of uncertainty, about benefits and risks. Neurotechnologies have the potential to affect bioethics, both in theory and in practice and require reflections on philosophical and ethical concepts: human dignity, personal identity, autonomy, mental privacy, accessibility and social justice. It also raises questions related to the accessibility to such new technologies which is a common ethical concern on new technologies (justice and equity). Issues will be different when neurotechnology is developed in the health sector or beyond (including gaming, marketing, education, etc.). Specific problems emerge in therapy and enhancement use contexts. 
35.	Assessment of ethical issues raised by the use of neurotechnology should consider the context of their application. In example, brain implants will not raise the same questions according to the level of uncertainties that both doctor and patient may accept if the possible benefits are important whatever it is used to treat neurological disease such as Parkinson’s disease or to treat mental disability. However, in this later case it has been reported a lack of discussion concerning core ethical issues (informed consent, risk, safety, and incidental findings) associated with either the conduct or results of MRI research on mental disabilities (Anderson et al., 2012). 
36.	Use of AI in combination with neurotechnologies raises issues of bias, discrimination and privacy. Brain information is probably the most intimate and private of all information. Digitally stored neural data could be stolen by hackers or used inappropriately by companies to whom users grant access (Drew, 2019).
III.1.1.	Cerebral/mental integrity  and human dignity 
37.	Given the growing neurotechnological possibilities to modify the brain, and consequently the mind, also in an invasive and pervasive way, it is necessary to consider the integrity of the brain and mind in the framework of the integrity of the human body
38.	Ienca and Andorno (2017) recognise ‘mental integrity’ as a value, in front of the neurotechnological possibility to provoke “direct harm” caused by “the unauthorized alteration of a person’s neural computation.” In this perspective ‘harm’ is the violation of integrity, and ‘benefit’ is the preservation of integrity. 
39.	As mentioned in article 1 of the Universal Declaration of Human Rights (UDHR) “All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience […].” In this perspective, integrity of the body, and brain/mind as part of the body, should be recognized, respected and protected from arbitrary alteration, modification, or manipulation, which violates it and causes harm to the subject (who becomes an object). This is also recognized by Art 3 of the EU charter of Human rights: “1. Everyone has the right to respect for his or her physical and mental integrity.”
40.	Human dignity is the fundamental value enshrined in the Human Rights doctrine and in the Universal Declaration of Bioethics and Human Rights of UNESCO. But the concept of dignity, because of philosophical pluralism, has different meanings, with different ethical implications. At least three meanings need to be mentioned in the context of the advancement of neurosciences and neurotechnology: the ontological dignity, which refers to the very being and nature of every human being as the permanent possibility to increase or decrease their own natural/intrinsic capacities; the transcendental dignity (Kant), each person has a specific value because of the possibility of autonomy, for being an end for themself; and the existential dignity where everyone has to construct themself by each and every act of their life, to do one’s best to decide one’s life through every action. This might be easier for one person than for another, but all individuals possess the same dignity defined as the will to construct one’s life by oneself. Furthermore, in libertarian views, dignity depends on the presence or absence of an individual’s ability to exercise their freedom.
41.	The IBC recognises the pluralistic debate on human dignity but emphasizes that the recognition of the dignity of every human being is linked with human rights, and includes the recognition of integrity of the body and equality. In this sense the integrity of brain/mind needs to be respected, considering any form of neurotechnological alteration, modification, manipulation a violation of the human dignity. Neurotechnology may also be a powerful tool to restore human dignity through rehabilitation and returning of autonomy.
III.1.2.	Personal identity and psychological continuity
42.	In the history of thought, two main approaches to the concept of personal identity have been developed. The first is a concept of personal identity based on substance: at different times, a person is identical to another because both are made of one and the same substance. The second approach is a relational and temporal conception of personal identity: at different times, a person is identical to another because relationships exist between them. As we will see, the determination of these relationships is variable according to philosophical conceptions.
43.	Contemporary reflection on personal identity has mostly been built upon the thought of John Locke (Locke, 1674), whether to validate or criticize Locke’s original ideas. As a 17th century philosopher, Locke distinguished biological identity (uninterrupted participation in the same life dynamic) from personal identity conceived in a relational way. Personal identity is based on self-reflective consciousness . The criticisms of this conception can be presented according to five major approaches. 
44.	The first approach is the psychological approach (Butler, 1736; Reid, 1785; Shoemaker, 1996) according to which psychological continuity exists between any two given moments of a person's existence, made up of an overlap of psychological connections such as memory, desires, likeness of character, etc. For the second biological approach (Wiggins, 1980), personal identity is based on a biological substrate, the identity of the person remains unchanged depending on whether or not he had such a desire, such a memory, etc. The third is the narrative approach which proposes that it is necessary for a person to integrate into the story of their life the events that affect them to give them coherence and intelligibility. The fourth approach, based on a social approach to identity (Nelson and Lindemann, 2001; Schechtman, 1996), highlights the contribution of third parties in the construction of a personal identity and in the recognition of this over time. The fifth approach is the reductionist approach (Parfit, 1984) that affirms that the facts about personal identity are facts about the brain, the body, or the interconnection of physical and mental events. 
45.	The psychological approach to personal identity requires that a neurotechnological modification preserves the possibility of establishing a link with mental contents (memories, etc.) and psychological characteristics of the past. The biological approach assesses the extent to which a neurotechnological intervention affects the biological substratum of personal identity. The narrative approach to identity takes as a criterion the fact that a neurotechnological intervention is not a substitute. The social approach relies on the perception by a third party of the possible modification of identity following a neurotechnological intervention. Finally, the reductionist approach judges a modification of identity following a neurotechnological intervention by establishing a link between the new cerebral characteristics and mental events.
46.	Continuity and distinctiveness of the self are bodily and ethically embedded. The way in which the self is bodily embedded is double: on the one hand, being a self presupposes ‘being a body’; on the other hand, being a self presupposes ‘having a body’ (Plessner, 1927). Authenticity can mean that a person is fully himself when he or she acts according to their desires and preferences or that if a person acts independently, responsibly, and sincerely, he acts authentically. 
47.	To understand if neurotechnology poses a threat, and what type of threat, to the personal identity and authenticity of the self, we consider two examples: first, that of memory modification techniques, then that of deep brain stimulation.
48.	Memory modification techniques (MMT) frequently use pharmacological means and may eventually (also) rely on implanting chips in the brain. These approaches make it possible to improve memory (memory enhancement), as in the case of cognitive improvement, for example. They also allow individuals to choose to alter the content of memory (memory editing). In the latter case, MMT can completely erase a memory, induce amnesia, or reduce the emotional impact of a painful memory and reduce the risk of post-traumatic stress disorder. Deleting a memory reconstructs the memory of past events and therefore personal identity. In itself, the reconstruction of this identity is not to blame; it is what happens when one integrates past experiences to repeat them or to avoid them in the future. The problem arises when this choice of memory content is imposed by a third party and the person can no longer relate to who they were before. Their perception of what they have experienced in the past is distorted and their responsibility may appear different, which affects personal identity and authenticity.
49.	Deep Brain Stimulation (DBS) can pose a threat to an individual’s body-to-body unity as their authentic self. Indeed, if the body regains appreciable autonomy in its movements, the mind can be disoriented by the active presence of the technical device. The individual experiences a feeling of alienation that bodily improvement cannot eliminate. The control exerted by the DBS on certain parts of the body is experienced as a form of subjugation of the person to the technical device. Added to this is the possibility that the device can be controlled remotely by a clinician, and this, perhaps, without the patient's knowledge. Note that this possibility is not specific to the DBS but to any device implanted or linked in one way or another to a human being.
50.	Depending on the type of pathology, the perception of the impact of DBS on personal identity varies. In Parkinson’s disease, it aims to reduce motor symptoms. In the context of obsessive-compulsive disorder, which appear earlier in life, it is the behaviour of the person, including their way of thinking and feeling, that is targeted. But even in this case, it is more precise changes in behaviour more than a total change in the person that seem to be put forward by the patients. In addition, depending on the type of pathology and the duration of the patient’s experience of this pathology, some people have integrated this pathology into their personal identity. They feel more authentically themselves with the pathology than without it. This indicates that there is no universally experienced correlation between the notions of health and authenticity, disease and alienation.
III.1.2.1.	Neurotechnology and the developing brain: personal identity of Children and Adolescent
51.	All the emerging issues related to personal identity and neurotechnologies raise the ethical need of precaution in front of the risks and uncertainties. Understanding the development of the brain and its relationship to other biological systems in the prenatal, perinatal, early childhood and adolescent periods, it is becoming increasingly clear that historic debates about the ascendency of genetics (nature) or that of the environment (nurture) have been superseded by an as yet-evolving understanding of the complex interaction between nature and nurture that shapes the growing child: emotionally, socially and behaviourally.
52.	The complex interaction between genetics and life experience shapes the development of neurobiological systems, particularly in the prenatal/early childhood and adolescent periods. Early experience impacts the structure and function of the developing brain. Epidemiological evidence reveals an association of experiences in the prenatal and early childhood period with later health and well-being (Black et al., 2017). The brain develops rapidly during this period, a time during which experiences shape the developing brain, with implications for health, learning and behaviour throughout the lifespan. 
53.	Neurotechnology have the potential to transform children and adolescents’ plastic, still developing brain in myriad of ways that will shape their future identity with long-lasting, if not permanent, effects. Neurodevices and BCIs embedded while an individual’s is still undergoing significant neurodevelopment (thought to extend until at least 25 years of age) make it difficult to distinguish charter traits and behaviour which can be attributed to the neurodevice versus the ‘normal’ maturation of the brain. This is a cross-cutting issue that needs to be kept in mind as we discuss other aspects of the ethical impacts of neurotechnology.
III.1.3.	Autonomy
54.	We understand autonomy as the ability to define our personal goals and the freedom to decide accordingly, implying intentionality, awareness and the absence of influences that determine it. We can consider that autonomous actions have to be analysed according to the following requirements: a) intentionality; b) awareness and c) absence of external influences that intend to control and determine one’s action (Beauchamp and Childress, 2001). Autonomy is the capacity that a person has to exercise their own individual freedom, which is recognized by the mere fact of birth.
55.	The increasing neurotechnological possibilities of cognitive monitoring/surveillance and influence in forms of manipulation or alteration of cognitive functions, brain/mental decoding, reading and (possibly) writing represent possible interferences with cognitive processes, and above all with free and competent decisions of the individuals. To lose one's autonomy means to lose a capacity but not the right to freedom. For this reason, the protection that society grants to the effectiveness of the right to freedom must take into account the degree of vulnerability of an individual person. 
56.	The human being is a social being in a situation of continuous external influences. Autonomy aims precisely at this capacity of distancing and personal choice in a context where influences are multiple. Through language, precisely, the human being is able to distance themself from these influences and use the leeway left to them by neurological constraints to articulate their behaviour to a system of meanings that they construct for themself in a personal way but in relation to their cultural and societal context. (Habermas 2008, Mac Whinney, 2015). The debate, both at the experimental and philosophical levels, the existence/nonexistence of free will (starting from Libet’s experiment ) is considered, in this context, not relevant for the bioethical discussion.
57.	Our actual increasing knowledge of the human brain can lead us to question if human beings can take, effectively, autonomous decisions. If neurotechnology can measure and change (improve, treat, obstruct, enable or enhance) our capacity, the degree of autonomy of that person after the intervention should be questioned, whether the decisions taken before the intervention remain after any changes, or not, and, if so, it is mandatory to reformulate the previously expressed declarations of will. Use of DBS offers examples of benefits (increased autonomy) as well as risks (Forgetfulness and word-finding problems, depression or suicide) (Zygmunt and Domitrz, 2020).
58.	In the context of neurotechnologies we have to consider two different perspectives: the first, autonomy to consent with respect to the use of neurotechnology on the subject’s body – as a participant in a research study, as a patient benefiting from a therapeutical application, or, as a consumer (of a medical or non-medical grade neurotechnology device). And the second, focused on the acquisition, data handling, use and sharing of neural data for different ends as developed in the legal chapter.
59.	The relevant ethical concerns here relate to the role of therapeutic neurotechnologies in restoring – or possibly disrupting – an individual’s capacity to exercise their autonomy and identity as a result of an intervening in the brain or manipulation of neural activity. 
60.	Brain damage or intervention may disrupt someone’s identity which results from each individual’s specific personal history. Neurotechnology used for rehabilitation can help to restore one’s capacities and their autonomy. 
61.	DBS may interfere with the natural process of decision-making, raising questions about the person self-governing, especially when DVS devices are controlled by closed-loop systems that increasingly use AI software to autonomously adapts their operation.
III.1.3.1. Autonomy and informed consent process
62.	“Consent is one of the basic principles of bioethics because it is closely linked to the principle of autonomy and because it reflects affirmation of human rights and human dignity which are the core values of democratic societies” (UNESCO, 2008).
63.	Article 6 of the Universal Declaration on Bioethics and Human Rights (UDBHR) provides that any preventive, diagnostic and therapeutic medical intervention as well as scientific research should only be carried out “with the prior, free, express and informed consent of the person concerned” (UNESCO, 2005). The Nuremberg Code underscores consent and is at the origin of the concept that participation in research is a voluntary activity. The Declaration of Helsinki also enshrines consent as a main guarantee (WMA, 2013).
64.	As an expression of autonomy, informed consent in neurotechnology is transversal to different situations such as the possible changes on the decision-making competence. Specific privacy issues have to be analysed for direct-to-consumer products, taking into account that, on the one hand, the use of a neurodevice may have direct and indirect influence on one’s privacy and, on the other hand, consent of use of personal data for broader purposes may have other impact on one’s privacy.
65.	The use of neurotechnologies may interfere with the cognitive process of perception and understanding of an individual. In other words, the use of neurotechnologies might call into question whether human beings can take, effectively, autonomous decisions. This could be at stake after a rehabilitation or enhancement of the brain. On the other hand, neurotechnologies may facilitate new methods to evaluate autonomy (e.g. by measuring brain activity).
66.	Ethical dilemmas in surrogate decision making are quite acute when it comes to neurodevices, given all the dimensions that must be considered and the dynamic evolution of brain functions and capacity (in relation to the device). Respect for the autonomy of children requires special attention in order to preserve their future capacity to make autonomous decision, once they acquire the maturity and the legal right to consent for their own. Although it is expected that parents act in their children’s best interest, requesting information of a predictive nature or making decision on behalf of a child whose potential health condition will most likely occur in adulthood could be inconsistent with respect for their autonomy.
67.	Concerning Deep Brain Stimulation, some neuroscientists acknowledge that “currently, consent forms typically focus only on the physical risks of (neuro)surgery, rather than the possible effects of a device on mood, personality or sense of self” (Yuste et al., 2017). Moreover, it is understood that “current trends in research study procedures often result in extremely long and legalistic informed consent forms, which ironically do little to protect the individual. Providing people with an ability to ask questions and understand in depth what they are signing up for becomes increasingly more important as interventions become increasingly more potent” (Jarchum, 2019).
68.	An individual has to receive understandable, relevant, structured and individually tailored information that makes it possible for that individual to make a decision on whether or not to accept medical intervention or to participate in scientific research (UNESCO, 2008). It has also been established that one of the most important aspects of information to be provided is information about possible risks and benefits related to a proposed medical or scientific intervention, this is a key component in obtaining consent. Medical or scientific interventions may involve a complex ratio of benefits and risks and it is the duty of health-care professionals to convey to a patient or research participant this information in an intelligible language (UNESCO, 2008). For neurotechnology, on many occasions the risks and benefits are still uncertain, therefore doubts about the validity of informed consent may arise because of the lack of required information.
69.	In the context of bioethics, some argue that, in view of the corresponding principle of non-maleficence there is an obligation to avoid harm in those new treatments where we have the knowledge about the harm they may cause, the long-term effects on the brain and on the person’s experience, the changes that may occur, the uncertainty of the consequences. “The obligation to avoid harm requires an ongoing commitment to develop a robust body of evidence, attention to the needs and vulnerabilities of particular individuals, and a willingness to reflect upon and review clinical practices and the development trajectories of these technologies” (Nuffield Council of Bioethics, 2013).
70.	On such circumstances, some recommend what they call the application of the ‘principle of caution’, referring to a “less restrictive standard of behaviour, one which is tempered by the recognition that some risks, and some uncertainty about risks, may be tolerated where technologies could make a significant contribution both to individual patients and to the public good” (Nuffield Council of Bioethics, 2013).
71.	Using AI tools also introduces ethical issues of which regulators have little experience. Machine-learning software learns to analyse data by generating algorithms that cannot be predicted and that are difficult, or impossible, to explain. This introduces an unknown and sometimes unaccountable process between a person’s thoughts and the technology that is acting on their behalf (Drew, 2019).
III.1.4.	Mental Privacy  
72.	As it has been explained in our previous Report of the IBC on Big Data and Health (UNESCO, 2017a), the right to privacy is tightly linked to the right to freedom with its diverse legal and ethical aspects like freedom of speech, of association, of location, of movement and space, of beliefs, thoughts and feelings, and of behaviour. Against this background, the IBC uses the term privacy in the sense of a right to respect for private life in relation to those areas of life that individuals want to keep reserved for themselves or, at least, for some specific members of their families or relationships.
73.	Neurotechnology may transmit brain data and digital data related to the brain activity of their users. Implanted neurodevices, such as those used in DBS, or even non-implanted might also record patients’ brain activity. Information collected and processed from neurodevices can be obtained and used to identify someone, or reveal their brain activity, particularly where this indicates a stigmatizing neurological or mental health condition or could otherwise be used for discriminatory purposes.
74.	‘Mind reading’, especially in relation to unexpectedly found data or detection, based on the neuroimaging of psychological states unknown to the individual and for which they were not considered in the range of possibilities or risks of detection can have personal implications and very complex social issues. On the other hand, such data may be obtained without the knowledge, thus, without the consent of the individual affected or even the awareness that such information is being taken.
75.	“The new possibilities of monitoring and manipulating the human mind through neuroimaging open the possibility of transgressing the right to privacy of individuals, accessing not only their behaviors, but also their thoughts, which can have consequences of great caliber" (Gracia and Jambrina, 2019). Brain recordings can be predictive of a neurological disease (for example early signatures of dementia that can be inferred from neuroimaging biomarkers). 
76.	Some of those consequences have already been raised by genetic research, mainly those regarding the access to such information by third parties (employers, insurance companies) (UNESCO, 2015b). The same may apply to neural data.
77.	So, the question is: may neural data be considered, and thus treated as health or personal data? And, if yes, what makes neural data different from other data? These are data from one’s brain. It has to be realized that the brain is what generates one’s mind. This is the only data that gets to one’s mental processes. If the assumption is “I am defined by my brain”, then neural data may be considered the origin of the self and require a special definition and protection.
III.1.5.	Accessibility and social justice
78.	The problems posed by brain disorders might be seen to present more significant challenges in less developed regions, where they may carry significant stigma and where public health infrastructure and access to treatments for such disorders are very limited. It is therefore desirable that research scientists, technologists, funders and industry partners should work together to develop ways of making access to novel neurotechnology a more realistic possibility for those who need it.
79.	Since neurological and mental disorders are of higher incidence in population in poverty, it is foreseeable that the medical applications of neurotechnologies may be under increasing demand. In such circumstances strong regulations will be needed both to ensure that potential uses of neurotechnologies meet the highest bioengineering and medical standards as well as to prevent deceptive advertising and misuses of them. These regulations should be developed embracing the principles of responsible innovation, say, ensuring public accountability, inclusiveness, representativeness, enforceability and active character during the process of both designing and apply them (Daniels, 2008).
80.	In contexts of deep social inequalities, neurotechnologies might potentially constitute a source of compensation to those patients that were suffering from neurological or mental disorders that could have been avoided if they had not had to live under poverty conditions. Conversely, limitations to access those technologies would constitute a source of greater inequality. In order to strengthen the former and reduce the possibilities of the latter, it is imperative that accessing potentially scarce neurotech-therapies (because of their potential expensiveness for low-income countries) be regulated by just distributive principles such as non-discrimination, highest potential medical benefit, social equity and transparency (WHO, 2016). In view of it, governments should begin to design and implement public policies focused in reducing brain health inequalities in the population –i.e. by ensuring high quality nutrition in early childhood as well as healthy and stimulant cognitive and emotional environments (Daniels, 2007; WHO, 2016).
81.	The principle of non-discrimination with specific consideration of the particularly vulnerable is expressed in many previous reports of the IBC including its Report on the Principle of Individual Responsibility as related to Health (UNESCO, 2019, pp. 38 and 42), Report on Big Data and Health (UNESCO, 2017a, pp. 33), Report on Social Responsibility and Health (UNESCO, 2011, pp. 8-9, 40, 45 and 63), Report on the Bioethical Response to the Situation of Refugees (UNESCO, 2017b, pp. 61 and 70), Report on the Principle of Non-discrimination and Non-stigmatization (UNESCO, 2014, pp. 27 and 29), Report on the Principle of the Sharing of Benefits (UNESCO, 2015a, pp. 43, 44 and 112), and Report on Updating Its Reflection on the Human Genome and Human Rights (UNESCO, 2015b, pp. 3, 19 and 44).
82.	Ensuring equitable access to neurotechnologies requires, amongst other things, effective governance of data sharing practices. Notably, cultural differences and a diversity of governance systems can complicate data sharing (Garden et al., 2019, pp.7). These complications can be addressed through responsible translation of brain research from the lab to commercialization. 
III.2.	Enhancement purpose
83.	Neurodevices have the potential to become integral parts of the lives of the people who use them and can cause changes in their personal and social identity. Neurodevices that can change a person's mood (e.g. DBS in major depressions) question the authenticity and adequacy of their emotions related to a real-life context and can create problems for the user, in terms of how relate to other people across time (i.e. with the device activated vs. deactivated). Neurodevices incorporate data on the abnormal state that is intended to be corrected and data on the state of normality that is to be obtained, thus bringing into question the concept of normality in the functioning of the human brain or body. Normality should be understood here as the functioning observed in healthy brains. Defining the concept of normality is also essential in order to delimit the pre-existing condition from the neuro-enhancement which can be obtained by using neurotechnology. In the future, sensorimotor normality could very likely be different in elite athletes and other performers (musicians, dancers, etc.), and neurodevices could provide all manner of performance enhancements in the sensorimotor domain. The IBC recognizes that the challenge of defining normality of brain functioning will vary across different domains and dimensions of the mind, such as sensorimotor performance, moral reasoning, face perception, etc.  	
84.	Neuro-cognitive enhancement  refers to interventions designed to improve mental and emotional performance, considered ‘normal’, due to recent advances in neuroscience and neurotechnology involving the brain tissue itself, as well as the neurophysiological mechanisms that govern cognitive functions, including psychotropic drugs affecting mental processes, neuroimaging technologies to assess or alter brain function via neurofeedback, neurostimulation technologies to transiently alter brain function, such as transcranial magnetic stimulation or transcranial direct current stimulation applied over the cortex, or surgically embedding brain implants and employing a brain-computer interface. Neurocognitive enhancement deals with diverse methods of intervention, more or less invasive with regard to the body, with short- and long-term consequences, that despite differences share common goals of intervention, which can be identified with enhancing human capabilities, ‘beyond’ therapy. 
85.	Moral neuro-enhancement (Persson and Savulescu, 2012) should be the use of drugs and technologies on healthy subjects to try to improve moral dispositions and capacities, such as the sense of justice, sympathy, empathy, altruism, cooperation, attenuating or removing aggressiveness, conflicts, prejudices and hatred. This kind of enhancement could be carried out by means of drugs, neuro-technologies with the activation of cerebral areas (like the amygdala) by means of deep brain stimulation or brain implants correlated to emotive responsiveness, the alteration of moral perception or the control of violent behaviour, a requisite of moral conducts (‘moral brain’). Little, if any, scientific literature supports such possibilities in real life yet.
86.	In the non-medical field (non-therapy derived) there are already games on the market using BCI technology that relies upon non-invasive brain imaging techniques such as electroencephalography (EEG) and functional near infrared spectroscopy (fNIRS). There is research activity to develop commercial games that are BCI-controlled. These neurotechnology based approaches are used for recreational purposes. A large number of people use these applications, with the lack of any clear evidence on benefits/risks, and the fact that they are not necessary and used without medical monitoring (in private settings).
87.	In the military (Italian National Committee for Bioethics, 2013). Novel neurotechnology have potentially applications in treating physical and psychiatric injuries in the military setting, enhancing fighters’ physical, cognitive, and emotional capacities, or by permitting neural remote control of weapon. Military applications of novel neurotechnology raise particular challenges because of the vulnerability of military in a hierarchical setting. 
88.	Augmentation technology may have positive effects on individuals with a low range of abilities, when introduced for therapeutic purposes in order to improve their capacities. In this sense it may have a positive effect for community and society. The blurring between enhancement and therapy comes out from the subjectivist view of health, considered a state of complete physical, mental and social well-being. In this perspective, enhancement is equated with therapy, insofar as a reduced capacity may be subjectively, socially and culturally perceived as a source of discomfort or an illness. In the blurring the subjective perception of ‘normality’ plays a role. The case of cochlear implants for deaf children, the particular concept of ‘normality’ that underlies the promotion of therapeutic purposes of such implants has, in fact, been challenged by deaf communities that do not consider their condition as something that needs to be corrected or improved.  
89.	Arguments in favour of enhancement (Savulescu et al., 2011; Harris, 2010). Starting from the idea that enhancement and therapy are interchangeable, contiguous and equivalent, improvement is considered part of human development, consciously or unconsciously, with reference to any individual or social opportunity, whether natural or artificial (pharmaceutical or technological). It is considered a ‘shortcut’, as a self-determined choice by a free individual, in a free market, in the libertarian view. In the utilitarian perspective, enhancement is considered a stage of evolution to be replaced by ‘deliberate choice’ of the selection process, allowing to reach the same result rapidly and with much less effort. Although possible negative outcomes still remain unknown, halting progress in this direction would imply hampering or preventing the possibility of accelerating human evolution. It is the theory of ‘self-evolution’ and ‘enhancement evolution’ that shortens time required for evolutionary progress over millions of years, allowing man and humanity to attain and realize their full potential, in order to balance the effects of the natural lottery, in physical and social terms. This approach justifies a ‘duty to enhancement’ as a ‘duty of beneficence’, which is not only individual but also collective. 
90.	The critical approach (Kass, 2002; Fukuyama, 2006; Sandel, 2007) to enhancement underlines the threats to dignity as it is an attempt to overcome the limits of nature (i.e., not accepting them). The use of technologies for improvement purposes can cause serious harm, disproportionate compared to the expected benefits, which coincide with the fulfilment of subjective desires. Excessively risky interventions with regard to achievable benefits (deemed ineffective, costly and burdensome for patients), alongside irreversible and predictably inconclusive interventions, cannot be ethically, deontologically  justified, even if requested by patients. In this view enhancement is a ‘fraudulent misrepresentation’ to the detriment of others. In opposition to enhancement, achievement encompasses the dimension of acquirement, in the sense of development and realization of potential naturally through an active effort and personal commitment that enable modification of one’s own natural capacities. In this sense, enhancement is expressed in the hidden pressure exerted by society on individuals to adapt to standards of mental efficiency in studying, working, sports performance, society in general. This gives rise to an enhancement divide, a divide between the enhanced and unenhanced. This presents us with problems of equality, inevitably introducing differences which increase disparities and discrimination between rich and poor, advantaged and disadvantaged. The strong push towards improvement re-proposes the ethical problem of eugenics, understood as the selection of the best: here on the basis of neurocognitive characteristics, jeopardizing “the inherent and therefore equal dignity of all human beings and renew eugenics, disguised as the fulfilment of the wish for a better, improved life” (UNESCO, 2015b).
91.	A special vulnerable category is the one of children. Special attention altogether must be dedicated to children, because of their particular vulnerability, the possible long-term effects (still not fully known) of this type of nootropic on a brain still in development. Ethical concerns also must be addressed concerning the use of helmet electrode recordings to monitor children’s brainwaves in order to survey awareness and attention, by teacher and parents. If these techniques contribute to an improvement of the pedagogical methods, they would be beneficial by contributing to the development of the child. On the contrary, if they are a new tool of surveillance and constraint, they appear to be contrary to the best interests of the child. Technology assessment should insure the best interest of the child.
92.	Paediatric enhancement is a rapidly developing area of concern, involving tools to influence children’s cognition in ways to improve their capacities. These issues appear in a different light given new paths in technological development and changing demands and expectations regarding parenting. 
93.	In addition to children, other person of concern are individuals with mental disabilities, persons who can easily be manipulated because of a specific weakness or dependence 
(e.g. drug addicts), captive institutionalized   populations (prisoners, pupils, adolescents in supervised education, young people in homes, members of the armed forces, refugees) (UNESCO, 1995). 
94.	The dual use of drugs and technologies, i.e. the fact that they may have clinical applications in therapeutic settings and may be applied in non-medical context with enhancement purposes, make the ethical justification a particularly sensitive and troublesome: a total ban on research and use of technology may hinder the development of a number of possible therapies a priori; at the same time, the discovery of certain technologies may encourage the use for enhancement purposes. The dual-use argument, which was generally brought up by bioconservatives to emphasize risks, is now being used by bioprogressives to justify some development methods.
95.	Novel neurotechnology in military settings have potential applications in treating physical and psychiatric injuries caused by combat, as well as non-therapeutic uses, such as using BCIs to enhance fighters’ effectiveness. Novel neurotechnology have also potentially applications in enhancing fighters’ physical, cognitive, and emotional capacities, or by permitting neural remote control of weapon. It is also plausible that BCIs or other neurostimulation approaches could be used for interrogation purposes. Military clinicians can play an important role in protecting the wellbeing of personnel with appropriate information. Military applications of novel neurotechnology raise particular challenges because of the vulnerability of military in a hierarchical setting.
96.	There are, until now, no research study or proof of safety and efficacy of the use of pharmaceuticals or neurotechnology in off-label use in medical field for enhancement purposes or for well-being (relaxation, sleep improvement…). A number of small studies, most of them occasional with non-systematic analysis using neurotechnology report improvements in participants’ performance in laboratory (for example memory or language skills, or in their mood). There is no statistical relevant sample, no repeated or repeatable test, no validate proofs. There is need for great care in extrapolating from small studies conducted under laboratory conditions to lasting real-world effects; the potential use of neurostimulation for neural enhancement is still far from proven. Not only have no trials been carried out on this, but it would also be extremely problematic from an ethical point of view to experiment such interventions on healthy subjects, given the absolute uncertainty and the possible high risks in the face of non-therapeutic and moreover implausible objectives. The obtaining of informed consent also represents a particularly delicate part of this and is an indispensable requirement to legitimate all research. The potential use of neurostimulation for neural enhancement is still far from proven. The discussion is more speculative than realistic. But applications are already applied or near to be applied both in the medical and non-medical field.
97.	The risk also is, in a competitive society, a sort of medicalization and pathologization (searching for drugs and technologies to improve performances) not considering the social/environmental causes and diseases mongering, or market of pharmaceuticals. The justification of risk proportionality- which is the level of risk considering the absence of a need due to a disease - is a particularly sensitive issue . These interventions are not necessary, but optional, selected by subjects experiencing non-disease conditions with the aim to feel ‘better’. There emerges a profile of responsibility of the health professionals who must ensure the appropriateness of the prescription and therefore prevent an ‘improper’ non-therapeutic use of these drugs.
98.	Uses of non-invasive neurostimulation or BCIs either for ‘enhancement’ purposes or gaming do not pose generally serious health risks. However, the large number of people that use these applications and the lack of any clear associated health benefits mean that it is important to attend to several ethical concerns. In particular, to minimize the pursuit of unnecessary brain interventions, there is a need to ensure the originality and rigour of research investigating non-therapeutic uses in humans and also to disseminate existing evidence. There is a particular concern in children, in whom the effects of neurostimulation or BCIs on the developing brain are not well known. There is a need of observational research with children who are already using neurotechnology to address this and also that advice is issued to teachers and parents about the current evidence of the efficacy of neurofeedback as an educational enhancement tool.
99.	It should also be considered that cognitive function can be improved in a more lasting manner through instruction, education and continuous training, a rich social life and from relationships, study, learning, continuous stimulation of hobbies and interests, and from leading a healthy lifestyle (in terms of nutrition, physical activity, etc.). It is a path that clearly requires a lot of time, but (perhaps) it is more respectful of the opportunities for growth and development of personal and relational identity.
100.	The use of neurotechnology for enhancement raises several ethical concerns about freedom and justice  .Those supporting the concept of human enhancement claim that all those worries can be overcome by the advance and wider availability of technology and that the limits of what it means to be human is a debatable issue.
III.3.	Neurotechnology and Clinical ethics
101.	Clinical ethics is a practical approach to making ethical decisions within a health care setting. It incorporates many of the ethical principles and rules fundamental to bioethics, such as respect for the autonomy of persons, beneficence and non-maleficence, confidentiality, informed consent, decision-making capacity, risk-benefit analysis, best interest standard, the right to refuse treatment, withdrawing treatment, and procedural and distributive justice. Most of these principles and values are inseparably linked with the individual and their concept of self, their human rights, and the function of their brain. 
102.	Ethical issues of neuro-technology within the clinical setting are therefore concerned with illness or damage to the brain that can lead to serious disorders that affect memory, cognition, movement, or consciousness. With the brain having limited capacity to repair damaged tissue, the novel neuro-technology has the potential to address some of the disabling effects of brain damage by intervening in the functions of the brain itself. However, its processes and uncertainties may challenge some of the principles and values that are fundamental to clinical ethics.   
103.	Any tension between clinical need and scientific uncertainty requires ethical prudence within the clinical setting. Uncertainty exists regarding the benefits and risks of these technologies due to their newness as well as the lack of a comprehensive understanding of how the brain works. The ‘special status’ of the brain therefore provides both a reason to exercise beneficence as well as non-maleficence (in all measures possible) by intervening when illness causes disorders of the brain.
104.	Application of the principals involved in clinical ethics to neuro-technological developments therefore requires prudent intervention in disorders of the brain while strict adhering to protecting personal privacy and the confidentiality of data, meticulous informed consent processes, and seeking to benefit others from the data obtained during the process of neuro-technological developments. 	
105.	Even in the context of clinical settings, special consideration should be given to vulnerable human beings and neurodevices. Procedures that are irreversible (surgical lesions) or that have the capacity to produce imprints in children’s brains with durable effect on their development, self-identity, liberty and capacity require careful consideration and close monitoring. For instance, the decision to surgically implant a cochlear device should take into consideration the stage of development of the child (including language development stage, neuromotor skills, etc..), but could also take into account other social considerations, in order to ultimately be “beneficial” to a human being, Indeed, deafness is a condition with very different social perception and social construction, and is considered by some groups of deaf people as a condition that does not need to be considered as a disease. Full consideration for issues relevant to neurodiversity will require further development, which is beyond the scope of the present report.
106.	As the clinical application of neurotechnologies may impact personal identity, autonomy, and privacy, accessibility to these technologies should always be underscored by justice and equity considerations. Further, neurotechnological innovations, such as artificial intelligence and brain-computer interfaces must respect and preserve people’s privacy, identity, agency, and equality.
III.4.	Neurotechnology and research ethics
107.	Research in neurotechnology must comply with accepted ethical standards for research mostly expressed in the Declaration of Helsinki, the 2016 International Ethical Guidelines for Biomedical Research Involving Human Subjects of the Council for International Organizations of Medical Sciences (CIOMS) and other international health research regulatory bodies. All proposals to conduct research that involve human participants must first be submitted for a review of their scientific merit and ethical acceptability by an independent ethical review committee, which must give its approval in order for the research to proceed.
108.	Individuals as well as whole communities may be vulnerable to exploitation in research, and so the sponsors of research, researchers, and other relevant stakeholders must make every effort to ensure that the research is responsive to the health needs and priorities of the community or population in which it is to be carried out, and that any intervention, product developed, or knowledge generated will be made reasonably available for the benefit of that community or population.
109.	As the neuro-technologic developments progress, ethical review of the process should also proceed hand-in-hand with the scientific development. Research outcomes such as the utility of ‘brain data’ should be subjected to ethical considerations such as non-discrimination and privacy protection (for example, to prevent re-identification and unauthorized re-use), and ensuring benefit also accrue to those who participated in the research. Researchers should also ensure that research participants who suffer injury as a result of their participation in the neurotechnological research be entitled to free medical treatment for such injury and to such financial or other assistance. 
110.	The exploring of neuro-technological developments for military purposes should be subjected to the ethical review requirements of research with human participants. Technological developments used for device control, deception detection and interrogation, as well as war fighter neuro-enhancement are examples of such research developments.  
111.	The problem of possible misinterpretation of data from neuroimaging is an ethical concern, whereby images that suggest a non-standard or exceptional neurological anatomy could be interpreted as being informative and/or predictive. In regard to predictivity, similarities also exist between the neurosciences and genetics in regard to population-based data and individual data which form a part of a person’s clinical file or records, amplified by issues surrounding the right to know or not to know. The right to refuse to be informed can only be exercised by persons who are in a state to express their view and, failing that, this right can never be exercised by the surrogate person, who would then make decision in place of another individual.
112.	The problem of incidental findings in functional magnetic resonance imaging (fMRI), and the frequency of discovering unexpected anomalies (or the difficulties of interpreting them) may pose ethical challenges such as determining appropriate strategies for communication, and how to handle clinically relevant incidental findings in cases where the person being researched did not express a willingness to be informed about result. Privacy of such information (and how it is being handled) may also be a concern for participants.   
113.	The principle of respect for autonomy may be in conflict with that of beneficence when persons subjected to brain imaging research renounce their right-to-know. In seeking to do good (beneficence), a researcher may deem it a responsibility to disclose the potential consequences of incidental findings discovered during brain imaging research, but doing so may be a breach of respect for a person’s right to self-determination (autonomy). Research teams in the field of neurosciences should always include clinical medical personnel to interpret incidental findings, and to give research participants the choice to be informed of incidental findings should they so wish. Extra caution should therefore be taken in the formulation of the informed consent process. Further, the research project must ensure long-term follow-up especially in relation to invasive procedures. 
114.	The question of the predictive value of brain images and the possibility to diagnose certain dispositions in the brain (e.g. the likelihood to get a certain disease) is also of ethical concern. Of importance will be ascertaining the probability or certainty of such a disposition, since the possibilities of false positives (diagnosing a pathology that is not there) or the possibilities of false negatives (the failing to identify or communicate a possibly life-threatening condition) may have major consequences on patients.
115.	Findings (incidental or not) that are of a predictive nature about conditions that manifest later in life, may represent a particular challenge if discovered in children. Respect for the children’s autonomy and future decision-making sometimes call for a special management of the information that has no immediate relevance for the child's health management. Such special care should be considered, for instance, when no treatment or preventive interactions are available.
116.	In the novel field of neuro-technology there is a clear risk to an excessive reliance on ‘single-patient’ case reports. Here, there is a tendency of ‘selective reporting’, which may be highly problematic. This implies a possible over-reporting of positive results, but can also be the basis for duplication of efforts. Research groups may therefore reproduce studies not knowing that similar studies have already been done and failed, which is highly problematic in the field of deep brain stimulation (DBS) due to the risks associated with brain surgery. Consequently, it is critical that all such studies are registered in a public data base (e.g. the WHO International Clinical Trials Registry Platform (ICTRP)).
IV.	NEUROTECHNOLOGY AND LAW
IV.1.	New dilemmas
117.	The development of neuroscience and neurotechnology opens up new dilemmas for human rights, in particular for the right to freedom of thoughts as the development of new technologies could give access to brain activities from which inference about individual thoughts can be made, as explained before. This is therefore challenging the basic assumptions of inalienable mental privacy. Secondly, some results of neuroscience also open up questions about the proper legal concept of free will and, therefore, of legal responsibility and liability. If free will does not exist, if it is considered as a human fiction, the individual cannot be blamed for their actions and consequently, he or she is not criminally prosecutable. So, all our legal model could be called into question. 
118.	These two perspectives of the legal dilemmas derived from the evolution of neurotechnology are related to the distinction made by Adina L. Roskies in her article “Neuroethics for the New Millenium” (Roskies, 2002), where she proposes a distinction between ethics for neuroscience and neuroscience of ethics. From a legal standpoint, the distinction could be between Law for Neurosciences, on other words, human rights for neuroscience and neuroscience of Law. 
119.	Neuroscience and Neurotechnology present themself as the science capable of revealing to us who we are, the secrets of our biological foundation and of the brain construction of our social, ethical, and therefore legal decisions. Neuroscience entered the free will debate through, among others, the work of neuroscientist Benjamin Libet in his empirical studies of conscious intention to act, studies that have generated widespread discussion and conflicting interpretation.
IV.2.	Consent
120.	Consent requires a capable mind and a free will. Neurotechnologies offer the potential to interfere (alter, mimic or enhance) with these essential attributes in a unique way. The IBC has already expressed its opinion on the notion and applications of informed consent in several reports, stressing that the main guarantee, which has traditionally been established to protect the autonomy of human subjects in health care and research, is consent. Autonomy and responsibility, as well as consent and protection of persons without the capacity to consent, are addressed in Articles 5, 6 and 7 of the Universal Declaration on Bioethics and Human Rights (UDBHR) (UNESCO, 2005).
121.	Fast advances in neuroscience and the possibility to identify the neural correlates of decision-making also opens up the possibility of acquiring accurate information about people’s competence to consent to specific medical clinical procedures and to medical research. The possibility to create a reliable neural test of competence and decision-making competence to consent opens up many questions: who will choose and set the threshold between what may be a competent or incompetent patient? When must or should this test be applied?
122.	An analysis of rational decision-making capacity involves: (i) the ability to understand and retain knowledge, or cognitive content; (ii) the ability to manipulate cognitive content critically; (iii) freedom of will; and (iv) the ability to express oneself. Ordinary people are assumed to be competent to consent; tests are generally only administered if there is a serious doubt as to the competence of particular individuals. Applying standards of decision-making capacity before accepting that someone is competent to consent should avoid false positives, but at the risk of allowing false negatives. 
123.	There is an international consensus that consent is generally required for medical interventions or for research on health , however, there are only rare occurrence of legally binding provisions regarding specific issues of informed consent on neurotechnologies or regarding specific matters such as neural data and privacy.
IV.2.1.	Consent to the Use of Brain Data
124.	Brain data (also called neural data) include data relating to brain structure and neural activity (see Introduction, paragraph 11). As information about the brain is intimate and private, its improper utilization may cause bias, discrimination, and privacy breaches, and digitally stored neural data could be stolen by hackers or used inappropriately by companies when granted access by the holder or owner of the data. Of note, thoughts are the basis of the freedom of opinion and expression that concerns the public and political sphere and nourishes the functioning of democracy. Furthermore, the brain generates the mood of a person, and so a person’s position on a particular matter may be detected and monitored within the clinical setting. Through such monitoring, others may come to know what a person thinks, as well as what they do not think within the perimeters of consciousness, which could constitute an affront to privacy of thought (mental privacy).
125.	Customarily (in mental privacy), human beings are able to filter the flow of information and decide which portions they wish to share and not share, in a conscious way. With neuroimaging technology, such mental privacy may be lost, and brain data could be extracted without the person being aware that their information was being read and extracted from them. Decoding of the brain may lead to neural data that involves not only conscious thoughts but in fact all brain activity, which may therefore be subject to commodification. Brain data is a much sought-after commodity which carries the risk of possible de-identification, hacking, unauthorized re-use of information, and digital surveillance. Predictive value of some neural data (for instance, brain imaging) calls for further precautions. 
126.	The European Charter of Fundamental Rights, at Article 3 – the Right to integrity of the person – states that everyone has the right to respect for their physical and mental integrity. This imposes the prohibition of any manipulation of a person’s neural activity without their informed consent. It also underscores the right to preserve one’s personal identity and mental activities from any external alteration by third parties unless specific consent is given. However, neurotechnology’s potential to intervene in brain activities raises several challenges when it comes to consent.  
127.	First, informed consent is predicated on the ability of individuals to make free and competent decisions, but in the context of neurotechnology, the technology itself may interfere with such capacity. Moreover, some information may be below the threshold of conscious experience. However, the technology may be able to access such information that is beyond the person’s awareness and so the criterion of informed consent would not be met. It should be noted that we analysed at length in our previous report on Big Data and Health (UNESCO, 2017a) the various ways to strengthen informed consent in the context of emerging technologies.
128.	Secondly, there is a perception that information and understanding prior to consent is often unknowingly incomplete since consenting individuals ignore or have difficulties grasping which and how much data they are giving up, how these data are being used and what might be learned by third parties about these data. This understanding assumes at start the availability of clear and intelligible information to research participants and patients about the collection, storage, processing, and use of personal brain data collected for health or scientific purposes.  
129.	Third, there are questions raised as to whether the traditional informed consent instruments and guidelines are adequate to uses of neurotechnology and if there is a need to provide additional safeguards to protect confidential information (or, as it is called ‘informational privacy’ and ‘brain privacy’) given their exceptionally sensitive nature.
130.	In fact, questions are raised as to whether brain data should be granted a ‘special status’.  What makes brain data different from other data? As described in previous sections of this report, brain data are central to one capacity, self-identity, mood, mental process, etc. Similar questions were raised with genomics data. Furthermore, brain data include an additional dynamic dimension, resulting from each individual’s history that sculpts individual brain structure and function. If we consider neural data just as data, it is not much different from other data. But if we consider what type of inference can be derived about the behaviour of a given individual and how such data might be used to change the behaviour of a person, then considerations are completely different from any other data. Of note, The General Data Protection Regulation (GDPR) makes a distinction between regular personal data and sensitive personal data. Article 4(1) of the GDPR defines personal data as ‘any information relating to an identified or identifiable natural person (‘data subject’). Sensitive data are ‘special categories of personal data’ that especially need to be protected. These are classical sensitive data such as one’s racial or ethnic makeup, political stances, religious beliefs, trade union membership, (mental) health condition, sexual orientation and criminal files and court proceedings, and GDPR adds biometric and genetic data. Brain data should be considered as sensitive data.
131.	As Ienca and Andorno (2017) explained, the adaptive ability that human rights law has shown in responding to the challenges posed by genetic technology may help to anticipate how this branch of law could evolve in the coming years in response to new issues raised by neuroscience. Since the end of the 1990s, the international community has made significant efforts to address a great variety of issues that result from the increasing access to human genetic data. In 1997, the Universal Declaration on the Human Genome and Human Rights (UDHGHR) was adopted to prevent that genetic information is collected and used in ways that are incompatible with respect for human rights, and to protect the human genome from improper manipulations that may harm future generations. The principles contained in this instrument were further developed in 2003 by the International Declaration on Human Genetic Data (IDHGD), which sets out more specific rules for the collection of human biological samples and genetic data. It is interesting to note that from the interaction between genetics and human rights resulted entirely new rights, such as the ‘right not to know one’s genetic information’, which is formally recognized by the UDHGHR (Art. 5(c)) and the IDHGD (Art. 10), as well as by other international and national regulations. In addition to the recognition of new rights, ‘old’ rights – such as the right to privacy and the right against discrimination – were specifically adapted to the novel challenges posed by genetics. This close connection between life sciences and human rights was further strengthened by the 2005 Universal Declaration on Bioethics and Human Rights, which comprehensively addresses the linkage between both fields (Andorno, 2013). This latter document sets out principles that are applicable not only to genetics but to other biomedical and life sciences issues. So, similarly to the historical trajectory of the genetic revolution and technology in the area of personal data, the ongoing ‘neuro-revolution’ will reshape some of our ethical and legal notions. In this new scenario, the right to cognitive liberty, the right to mental privacy, the right to mental integrity, and the right to psychological continuity can play a main role.
132.	Use of neural data outside the strict context of providing health care to an individual (for instance research context) raises issues of privacy in relation to the most intimate information about an individual. Sought after neural data may not be truly anonymous, as a large body of evidence indicate that data signal cannot be divorced from the identity that produced that signal. So, for example, the electroencephalography (EEG) signal has been demonstrated to be a unique biometric identifier.  
133.	Within the domain of brain data, there is the risk that the de-identified data may become identifiable subsequently, unless the means to protect mental privacy is specifically designed during and within the development of the technology itself.
134.	In what concerns the consent to share data, alternative systems, such as the opting out system, are also suggested, with the consideration to treat neural data in the same way that organs and tissues are treated in some jurisdictions, for example for transplant purposes, where individuals would need to explicitly opt in to share neural data from any device. “This would involve a safe and secure process, including a consent procedure that clearly specifies who will use the data, for what purposes and for how long” (Yuste et al., 2017). 
135.	Even with a renewed approach to consent, neural data from many willing sharers, combined with massive amounts of non-neural data — from internet searches, fitness monitors and so on — could be used to draw ‘good enough’ conclusions about individuals who choose not to share.
136.	Finally, there is a need to review regulatory matters in other studies outside medical research, such as the case of neuromarketing companies which may run studies involving human subjects without a clear informed consent and an approval from an ethics committee. 
137.	Robust protective measures are required in order to preserve human rights, including autonomy and liberty, of vulnerable human beings. This is especially the case for children, whose brain data could be defining not only to shape them (their perception as a human being) but could impact their future opportunities (employment, insurance, etc.). 
138.	Ethical issues surrounding the commodification of ‘brain data’ (Minielly et al., 2020) will needs to be addressed, as will potential outcomes of neuro-technology such as affective computing, neuro-marketing, and human rights. Appropriate governance structures will also need to be developed to ensure adequate regulation of these new developments to protect the well-being and non-exploitation of all humans involved in the process and for how long (Yuste et al., 2017).
139.	Non-medical applications also need better rules of consent, some being common to rules used on medical applications, others being adapted to fully respect individual consent in the specific context of use. In example, in neurogaming, some possibilities would be to promote opt-out of data sharing as the default mode, and to clearly specify who owns the collected data.
IV.3.	Neuroscience and human rights: the impact of neuroscience development in the right to freedom of thought
140.	The right to freedom of thought and conscience has been proclaimed in all the main international legal regulations. Article 18 of the Universal Declaration of Human Rights proclaims that “Everyone has the right to freedom of thought, conscience and religion; this right includes freedom to change his religion or belief, and freedom, either alone or in community with others and in public or private, to manifest his religion or belief in teaching, practice, worship and observance” (UN, 1948). These rights are equally provided for in article Articles 18 of the International Covenant on Civil and Political Rights (UN, 1966a), 13 of the American Convention on Human Rights, 9 of the European Convention on Human Rights, 8 of the African Charter on Human and Peoples’ Rights (AU, 1981) etc.
141.	The right to freedom of thought appeared as a fundamental and human right at the beginning of the constitutional revolutions of XVIII and XIX centuries . The right to freedom of thought is considered, for the Courts, the precondition of many fundamental rights such as freedom of ideology, freedom of religion. So, the need to protect it constitutes the way to guarantee the others. Freedom of thought has had two dimensions, the internal, where the individual has the right to adopt a personal position about life and to judge reality according to their personal convictions, and the external, based on agere licere, where the individual is able to express or act according to their ideas. As Mill describes it, that sphere includes: the inward domain of consciousness, demanding liberty of conscience in the most comprehensive sense, liberty of thought and feeling, absolute freedom of opinion and sentiment on all subjects, practical or speculative, scientific, moral, or theological. This might mean that it is at the top of the order of moral importance; but the sphere could be ‘first’ in the sense that it is where human freedom begins, for individuals or societies, or it might be paramount both with respect to its moral priority and its generative significance. Even Mill claims that the freedom to express and publish opinions is “practically inseparable” from freedom of thought, and “almost of as much importance as the liberty of thought itself.” And Rawls proposes that one should include freedom of thought as part of what he calls a fully adequate scheme of basic liberties. Rawls is clear that freedom of thought counts as one of the basic liberties— he lists freedom of thought first among them— and he suggests that those liberties jointly hold the status of a primary good. Rawls suggesting that freedom of thought has an essential role in specifying a just political procedure and maintaining that the constitution of a well-ordered democracy must guarantee freedom of thought in order for political liberties to be exercised in a free and informed manner.
142.	Therefore, the right to freedom of thought is related not only to human dignity because human beings are expressive beings which need to conform their thoughts as an essential precondition of their freedom of expression, but also to democracy because that freedom is a precondition of a fair and just political system. There is a direct connection among freedom of thought, rule of law and democracy. Freedom of thought is not only included on lists of primary or cardinal rights and liberties, in notable philosophical treatments; it is often listed first.
143.	Traditionally, the internal dimension was not controversial for Law, but it was proclaimed in all the Constitutions and International Conventions because it was considered a necessary precondition of the external one, as we said before. For Law, right to freedom of thought matters because its nature of precondition of liberty and freedom of expression and acting according to their thoughts. Even, the Courts have protected this internal dimension through the protection of the necessary means for the individual to develop their owns thoughts (for instance, access to publications, media, etc). Right to freedom of thought has appeared or has been invoked in front of the Court as a way to protect, not the thoughts itself, but the means to conform those thoughts.
144.	Considering the development of some technologies, we may one day be faced with machines that might be able to control the brain activities of individuals, in such a way that it controls their ideas and thoughts. Will thought be limited by neurotechnology? Will individual be punished by their thoughts and not only by their actions?
145.	Some authors have proposed the idea to develop a new cognitive freedom able to address these new conflicts. A sort of liberty of the mind using the terms of Charles Fried (Fried, 2007, pp. 95-123, 160, 167). A new cognitive freedom in the sense of protecting also the internal dimension of thoughts. The position of the public powers won’t be then to guarantee only the means to allow the individual conforming their thoughts, but also to guarantee the individual from any intromission in their thoughts. Will this be possible? What are the legal measures to guarantee this new perspective of the protection of the right to freedom of thought?
146.	Recent developments of the science of behaviour enable some ability to predict and also to interfere with an individual’s behaviour. However, the impact of such developments is over the actions or expressions of the individual, not over their thoughts. Through a WhatsApp message, for example, we can understand what an individual is expressing, but it is not possible to find out what they are actually thinking, unless we can access their thoughts. While it is well known that humans do not always act in strict correlation to our thoughts, we have also always had the guarantee that our thoughts are hidden from third parties. This can be considered one of the most relevant perspectives of our dignity and, above all, an important rule of social coexistence. Our dreams and opinions make us free considering that they are preserved from the control of the others and, because of society’s organization, we are able to think whatever we want while ensuring our actions adhere to social norms. Our cognitive capacities are also the basis of our relationship to others, and are essential for building a human society. 
147.	The improvement of new technologies and apps in the area of personal computers and the internet provoked the need of a new regulation of the new personal data. We could propose similar regulations, a new thoughts protection, a new habeas cogitandi o mens, considering the development of new technologies which are able to control not only our actions or decisions (current personal data), but also our internal thoughts. Informed consent, proportionality and different forms of guarantee confidentiality such as anonymity are called to play again a main role. A right to keep their thought and their personality away from any kind of intervention aimed at damaging individual liberty can be developed based on the principles and rules of data protection.
IV.4.	Freedom of thought is not cognitive liberty
148.	As we said before, some authors consider that the current legal model developed for data protection and for biotechnology is useful to address some of new issues and conflicts posed by neurotechnology from the human rights perspective, but not enough because some of the issues and conflicts are new and different to the previous ones solved by Law. Consequently, we should develop and include new rights and guarantees. As a main initiative, some have proposed  to develop a new right to guarantee an individual’s cognitive liberty in the new context of neurotechnology development. This is an adaptation to the traditional freedom of thought when the new context could transform something internal into something controllable by external tools. Are we talking about the same right in a different context or not ? Negative rights impose obligations on governments and other citizens to refrain from interfering with the rights bearer. By contrast, a positive formulation of cognitive liberty supports that the existing neuro-technologies should be widely available to anyone who wants them.
149.	If we analyse the different definitions of cognitive liberty, we will find a relationship between this right and enhancement in the sense that the new neurotechnology will be able to improve individuals’ mind power. So, considering this perspective we are talking about something directly related to the transhuman movement and its proposal about taking advantage of science evolution to develop ‘better’ and more powerful human beings. By this formulation, this new right will have positive meaning, not a mere liberty . It is not a mere liberty related to dignity and privacy in the sense of “leave my thoughts alone”, but something more related to a right to control decisions made about one’s own brain. This right includes not only a negative sphere but a positive one in the sense of giving the individual the faculty to accept the use of some neurotechnology tools to improve and, therefore, to enhance their brain.
150.	In this definition, there is something more than privacy, meaning that our thoughts must remain private until one decides to share them, as a legal guarantee to protect individual freedom and self-determination from the State and other subjects, but particularly from the State or commercial entities: a sort of protection from the coercive and non-consensual use of neurotechnology. This relates to something more than autonomy, with respect to the idea that every human being must be able to think independently and use the full spectrum of their mental faculties. In addition, cognitive liberty includes a third sphere, choice, proclaiming that the capabilities of the human mind should not be limited.
151.	On the other hand, cognitive liberty might be understood as a negative right and not a positive one (Ienca and Andorno, 2017). According to this understanding, cognitive liberty is a prerequisite of all the rights focused on neuro aspects. Cognitive freedom is a new form of freedom of thought that takes into account the power we now have, and increasingly we will have, to monitor and manipulate cognitive function (Lavazza, 2018). Faced with potential new threats to mental integrity due to neuroscientific techniques, attempts have been made to introduce new human rights, specifically aimed at safeguarding the right to cognitive freedom, the right to mental privacy, the right to mental integrity, and the right to psychological continuity. It is also important to protect brain data that can be used to give access to the (more or less precise) prediction of the person’s behavioural patterns through their neural connection and activation patterns. In fact, such information can be used for forms of prevention/discrimination based on an individual’s hypothetical attitudes, or even to implement forms of forced re-education or compulsory moral bioenhancement (Baccarini et al., 2017).
IV.5.	Neurotechnology, law and democracy
152.	The development of neuroscience and neurotechnology is not only affecting the concept of freedom of thought as a human right, but also the legal and judicial system, based on the idea of free will. The only justification to criminalize and punish some actions of the individuals is their free will. Without assuming the concept of free will, Law cannot be understood and accepted.
153.	Libet experiment opened an interesting academic argument about the future of our legal system and, specifically, about our Criminal Law model based on free will. Of note, some authors proposed that neurosciences inevitably lead us to consider free will as a pure illusion and therefore as a kind of necessary social convention. This appreciation is very problematic and is not unanimously accepted even within the scientific community (c.f. G. Edelman, E. Kandel, A. Damasio, St. Dehaene, etc.). Moreover, many philosophical works tend to establish the contrary (Merleau-Ponty, Varela, Habermas, etc.).
154.	Law is based on social conventions but not only on science. Science is important for Law because it provides elements to make legal decisions, but science is not the foundation or essence of our legal systems. For instance, the development of genetics has been very important for the crimes investigation and for judging them.
155.	The example of democracy can be a good one for our current debate. Democratic systems are based on social conventions, not on scientific evidence. For democratic systems, the scientific measurement of the intelligence of the voters is not relevant, unless some cases of mental incapacity to make decisions. Each voter is entitled with one vote without consideration for their intellectual preparation or its mental capacity from a neuroscientific perspective. All are equals in front of the ballot box and all are also equals in front of the legal systems for similar social and anthropological reasons. Such legal system is based on freedom and equality among citizens and it is still science-fiction to imagine that such social convention might change in the context of a huge improvement of neuroscience and neurotechnology.
156.	A reasonable organization of human social life is not possible without the reciprocal recognition of freedom. The improve of knowledge about neurological processes is necessary to improve the functioning of Law and, especially, of criminal Law, but it is difficult to believe that it can replace it in our societies.
157.	Therefore, we can address a huge development for neuroscience and neurotechnology without devaluating the role of Law and Justice. Neuroscience will provide Law with important new scientific evidences, as genetics did, mainly in the area of criminal competence, but free will as a social convention will be still there. Neuroscience will play and is currently playing a role in the area of the evaluation of mental capacity but not to dismiss free will as a legal foundation of Law. Brain imaging techniques, for instance, might possibly contribute to more evidence-based decisions in criminal justice, from investigation and the assessment of criminal responsibility, to punishment, rehabilitation of offenders, and the evaluation of their risk of recidivism. The tools offered by neuroscience could potentially play also a role in civil law procedures, for example, in the assessment of an individual’s capacity to contract, or of the severity of the plaintiff’s pain in compensation claims. New and more reliable lie detection technologies based on our knowledge of the brain functioning might help to assess the reliability of witnesses. Memory erasure of recidivist violent criminals and of victims of especially traumatic offences (e.g. sexual abuse) is also mentioned as another possibility opened by our new knowledge of the brain (Goodenough and Tucker 2010; Ienca and Andorno, 2017). The neuroscientifics as expert witnesses have an important role in front of the Court, but he or she won´t decide. The Judge will always make the decision.
158.	The main question could be now if the human irrationality that we have accepted in many areas, such as Justice and democracy, is at its very end. In any case, it is important to underline that irrationality is extremely human and as humans we need something more than science. Social conventions and solutions play an important role in our societies apart from science. A new paradigm based only in science is called to fail, as positivism did some decades ago (Greely, 2009) . And as Kant said many centuries ago, a merely empirical doctrine of right (we can add “of Law”) is a head that may be beautiful to look at, but unfortunately it has no brain.
159.	Thinking that the brain / moral / law relationship is everything can lead us to forget that the measure of law, the very idea and essence of law, is human, whose nature results not only from a very complicated mixture of genes and neurons but also of experiences, values, learning and influences from our equally complicated socio-cultural life.
160.	Habermas (2008) argues that the categorical error that would be made when we try to explain the performance of the human being only from a neurobiological perspective is that the essential feature that defines and differentiates human action is not explained by reference to causes such as the behaviour of the apple falling from the tree. Human action results from motives, intentions, plans, and reasons; and the reasons for action arise from individual experience and social interaction and communication. The Libet findings of unconscious brain activities involved in decision processes do not change the definition of the decisions that we make in a moral or legal framework. 
161.	Neurotechnology is a revolution, like all scientific revolutions, in tools. These tools are giving us the ability, for the first time, to look inside living, healthy human brains and to see what is happening. And they are giving us the chance to begin to correlate the physical states of the brain, revealed by these tools, with the states of the mind that are produced by those activities (Greely, 2009). So, as mere tools we should not transform them in a new philosophical, ideological or legal paradigm. Tools are developed to serve human beings, not to transform our social conventions which have been the real to develop a world based on the relevance of human rights.
V.	GOVERNANCE OF NEUROTECHNOLOGY
V.1.	Responsible innovation
162.	As described in the previous sections of this report, neurotechnology has the potential for tremendous benefits in health, education and social relationships, but also holds the potential to deepen social inequities, to harm individuals’ privacy and to provide methods of manipulating individuals (such as technologies of persuasion and personality-altering technologies), and consequently the potential to challenge some basic aspects of human dignity, such as privacy of mental life or individual agency. Such challenges call for a responsible research and innovation approach.
163.	The regulations in science and technology are late if they respond only to concrete realities generated by technologies already available or even widely applied. For this reason, it is necessary to anticipate the effects of implementing neurotechnology, using scenarios in which society, science and future technologies are imagined and how they will interact (the so-called ‘sociotechnical imaginaries’). As all emerging technologies, neurotechnology development needs an “ethical-by-design” approach. The spectacular development of neurotechnology as well as new biotechnologies, nanotechnologies and ICTs make machines more and more humanoid, and people are becoming more connected to machines and AI, indicating a pressing need for anticipatory governance. 
164.	Indeed, fostering responsible innovation in neurotechnology (OECD Recommendation on Responsible Innovation in Neurotechnology, 2019) requires clear guidance on “how to identify and anticipate the broader impact of neurotechnology on society; and how the potential of novel neurotechnology is communicated to the public to both inform and to avoid hype” (Garden et al., 2019). Notably, “neurohype and false promises can give rise to mistrust and unintended social effects” (Garden et al., 2016). Consequently, one of the relevant policy considerations that requires attention is the need to ensure “strong ‘‘technological push’’ of brain science towards addressing pressing societal needs”, which can be achieved through public deliberation approaches across sectors (Garden et al., 2016).
165.	Differences in the definition and framing of Responsible Research and innovation (RRI) have made it challenging to apply the RRI framework in governing emerging technologies such as neurotechnology (Garden et al., 2016). However, there seems to be an agreement that the RRI framework is designed to enable stakeholders to collectively discuss avenues for advancing societal goals through technology (Garden et al., 2016; Owen et al., 2013).  
166.	The three questions that should guide the RRI process as suggested by Garden et al. (2016) are first: who benefits, how, and what are the (potential) costs? Secondly, what are the uncertainties and what are the potential implications if we are wrong? Thirdly, who controls access to the science and the technology, and under what conditions? Addressing these questions requires continuous engagement with relevant stakeholders.
167.	In order to protect the dignity of people and humanity as a representation of the group to which we belong and which is distinguished by freedom, it is of capital importance to formulate appropriate regulations for neurotechnology. In agreement with principles of good governance of technologies, openness, transparency, honesty and accountability, such regulations may include a personal oath in which each inventor, producer, and seller of neurotechnology undertakes to use them and offer them for the benefit of users and in accordance with the respect of their human rights. A governance framework may also identify neuro-rights that should be stipulated in a yet to elaborate “UNESCO Universal Declaration of Human Brain and Human Rights” that should be elaborated in a UNESCO Universal Convention that will invite governments to establish a specific legal framework for such rights to be applied and sanctioned if enforced.
168.	A major concern is the risk of new inequalities resulting from neurotechnology, particularly due to and adding to social inequalities. Specific mechanisms should be used in this regard such as free licensing for developing countries or fostering participation in patent pools to make the products affordable: “Responsible transfer metrics could include considerations of social benefits and impact (e.g. free licensing for developing countries), equity (e.g. patent pools), and anticipatory governance (e.g. as part of business plans), and adjust incentives and transfer contracts accordingly (e.g. required RRI boards for start-ups) (Garden et al., 2019). These can be achieved through optimal use of suitable competition policies, which have been hailed for driving innovation and access. Competition policies can be used to eradicate restrictive conditions in medical technology licensing and abuse of intellectual property rights by holders (WHO, WIPO and WTO, 2013).
V.1.1.	Engaging with the Public
169.	Responsible innovation in neurotechnology must be a collaboration between science and society (Garden et al., 2019). In the process of developing neurotechnologies, it is essential to include the perspectives (needs, concerns and experiences) of the people who will use them. Education regarding what neurotechnologies are and what effects can be expected or feared is obviously a basic need. But education is not enough. Neurotechnology development requires engagement with the public, which should be focused on two-way, rather than one-way, communication with the public (Stilgoe et al., 2014). Consequently, engagement must be inclusive by embracing public values in the innovation and development process (Garden and Winickoff, 2018). Innovators in neurotechnology should therefore consider the social value and impact of the technology by ensuring responsible innovation. This requires an evaluation of the ethical and social aspects of the technology. Engaging the public “is critical for developing trust and trustworthiness with end users, and can help tailor emerging technologies better to the needs of those they are designed to help” (Garden et al., 2019). This also helps to eliminate unrealistic expectations that can erode public trust.
170.	Educating the public on the possible cognitive and emotional effects of neurotechnology is a pre-requisite to public engagement. However, faced with such cutting-edge technology, bridging the knowledge gap between citizens and experts can be quite a challenge. Furthermore, the distribution and access to neurotechnology, both from the point of view of their access and from the point of view of the knowledge needed to use them, is unequal between countries and regions of the world and also within the same country due to the social stratification (the so-called ‘technological divide’). Education should target various public, including teachers. UNESCO may provide some training and facility building supports.
V.1.2.	Engaging with the Industry
171.	Key players from the private sector as well as start-ups are at the forefront of neurotechnology innovation. They serve all sectors of societal activities such as health, education, military, gaming and entertainment, etc. Consequently, the private sector should be involved in responsible development of technology as soon as possible, namely at the preliminary and early stages (Garden et al., 2019). 
172.	Obviously, it is expected that individual companies must be responsible for their neurotechnology products, and to make responsible claims about them (McCall et al., 2019).  Neurotechnology development must be guided by standards, good practices and ethical norms, resulting from the legal and ethical regulation of the field. Of note, the EU Medical Device Regulation (May 26, 2021) increases the accountability of all stakeholders and focus on the entire production process of devices and not just on their marketing:
a)	Vigilance and post-marketing surveillance: Medical device manufacturers must have plans for post-marketing surveillance, continuous evaluation and improvement.
b)	Reinforcement of the responsibility of manufacturers, importers and other actors involved in marketing for regulatory compliance.
c)	Reinforcement of verification processes and obligation to submit internal verification programs to the regulatory authority of each European country.
d)	Identification of devices: obligation of traceability.
e)	Information: Manufacturers will be required to provide a clear and understandable summary of the safety and clinical performance of devices.
f)	Clinical evaluation, post-marketing follow-up, clinical research: stricter rules.
173.	However, neurotechnology raises such a unique set of societal and ethical issues that it further requires proactive actions beyond regular product warranty. 
174.	Such good practices include having harmonized standards for neurotechnology innovation to ensure a positive impact on health and society. This is because “the standardisation of neurotechnology system specification and interoperability helps communication and collaboration across major brain research initiatives and the private sector” (Garden et al., 2019). Standardising personal brain data collection, curation, and sharing are essential for driving new discovery and obtaining broader value from the data (Garden et al., 2019).
175.	The development of gender-neutral products and ensuring inclusive innovation are amongst elements of good practices that ought to be considered (OECD Recommendation of the Council on Responsible innovation in Neurotechnology, 2019). Privacy by design should also be a backbone of any neurotechnology device, given the highly sensitive nature of brain data. 
176.	Finding an appropriate balance between regulating such best practices and stimulating responsible and ethical innovation is key. To achieve this, it is suggested that perhaps an effective approach would be to engage the professionals involved in designing neurotechnologies (engineers, programmers, etc.) in subscribing to an oath of responsible innovation bearing some similarities to the values upheld by the Hippocratic oath. If such an oath is supported, appropriate structures should be developed to review and oversee its application. 
V.2.	Public-private partnership  
177.	In recent years, research and development are often driven by public-private partnerships (PPPs). In the current era of “Open Innovation”, industry looks to partners from institutions of higher learning (who perform publicly-funded basic research) for useful inventions, after which industry will collaborate further in research, development and commercialization of the invention, resulting in shared Intellectual Property rights. Neurotechnology is an area that has the potential of exploiting this PPP. The invention and subsequent development and commercialization of the Magnetic Resonance Scan (MRI) and the Positron Emission Tomography (PET) scan are good examples of previous PPPs. PPPs offer tremendous opportunities for companies to make products ranging from medical equipment to industrial and consumer products. Among these are neuroimaging and other neurodevices, many of which are designed to collect brain data that can be used to treat illnesses such as Parkinson’s disease and debilitating conditions such as blindness, and to further our understanding of brain function. Brain-computer interfaces are areas of research which are not only important for medical purposes, such as repair of sensory loss, but also impact on the development of artificial intelligence. They are also important for learning, developing our understanding of individual and group psychology, and marketing purposes.
178.	On the whole, while the private sector has the goal of making profits from investment in products and data from neurotechnology, the scientists and engineers in the public sector aim to gain knowledge on the physiology of the brain and neural systems not only for academic purposes but also to serve the public in providing tangible solutions in neurology, psychiatry, cognition, learning, social services and other areas. Partnerships can be a win-win situation and many have been formed between the public and private sector, such as the BRAIN initiative, launched in 2003 with the US National Institutes of Health as the leading member, which aims at achieving a dynamic picture of the brain that shows how individual cells and complex neural circuits interact in both time and space. It provides funding opportunities into such research areas as devices for recording and modulation in the human central nervous system, next-generation human brain imaging and ethical implications of advancements in neurotechnology and brain science. Around the world, a number of large research programmes on neurotechnology are funded by governments with input from the private sector.  These include the Human Brain Project launched by the EU, the Blue Brain Project initiated in Switzerland, the Brain/MINDS project launched by Japan, the China Brain Project, and several other initiatives now included under the auspices of the International Brain Initiative (IBI, 2016). These projects largely aim to use information and communications technology, artificial intelligence and biomedical and related technologies to understand and modify brain functions and neurotechnology in general, and making use of the knowledge gained.
179.	Public-private partnership can potentially yield further benefits to consumers and the general public. From the knowledge gained from such partnerships, consumers and the general public can benefit from better prevention and treatment of brain and other neural disorders, better learning capabilities, better human-human and human-machine communications, and other benefits. These partnerships can provide much needed investment for start-ups to thrive in neurotechnology innovation. It is also through public-private partnerships (PPPs) that we can ensure “new approaches to information sharing, intellectual property (IP) management, public engagement, and incentivising open science and responsible innovation” (Garden et al., 2019).  Additionally, such partnerships can help in tackling responsibility issues (Garden et al., 2019). However, the balance between public and private interest is crucial in determining the direction of progress of neurotechnology, and also in safeguarding against misuse of the technology. 
180.	In agreement with the principles of accountability and responsible regulatory stewardship, protection of personal identity and personal data are paramount. Good governance is necessary if the private sector should be entrusted with the task of collecting individuals’ brain data; regulating the commercialization of brain data; ensuring that the recording and modulating of human thoughts and other brain processes are done ethically; regulating the use of data generated from public-private partnership; the use by public sector of the advances gained from public-private partnership; safeguarding the collection and collation of brain data from the public by governments and other entities; allowing for public-private partnerships to the access of such data; and modulating public and individual brain processes. The issues raised by George Orwell in his novel “1984” are most pertinent in this regard and these and related questions form the core of ethical considerations in public-private partnership in neurotechnology.
181.	It is important that both public and private sector researchers be aware of, actively engage with, and address the potential conflicts of interest and other ethical and legal issues, which include: inadequate risk assessment on misuse of technology and data, premature commercialization, preferential benefits to private sector partners at the expense of the public, commercialization of such technologies as brain monitoring and behaviour modification, ethical and legal concerns on research and products/procedures resulting from the partnership.
182.	The public should also be aware of potential consequences of various public-private partnerships on neurotechnology, which may have potential impact on their lives and livelihood, ranging from use of the technology in monitoring and controlling behaviour, manipulation of mass psychology, influencing the direction of education, and influencing political outcomes. Civil society organizations and pressure groups formed by members of the public can help to interrogate the aims and modes of work of researchers and institutions, including those involved in public-private partnerships, and should participate in debates on ethical aspects of neurotechnology, so as to ensure good governance and help answer the questions of ethical conduct in neurotechnology (Garden et al., 2019).
VI.	RECOMMENDATIONS
183.	In the framework of this report, we have identified the benefits that may result from the development of neurotechnology, but also some fundamental human characteristics and their associated human rights that might be challenged by this technology. These include:
a)	Cerebral/mental integrity and human dignity.  Given the growing neurotechnological possibilities to modify the brain, and consequently the mind, in an invasive and pervasive way, this reinforces the idea that the value of the person ought to be considered as a whole. 
b)	Personal identity. This refers to our ability to think and feel for ourselves, regardless of how neurotechnology is applied. It is possible that when connecting brains to computers, an individual’s identity can become diluted, in part because algorithms will help them make decisions and can consequently blur the participation of the individual-self. Thus, we need to preserve individuals’ control over decision-inducing neurotechnology.
c)	Freedom of thought, cognitive liberty and free will. Brain activities allowing free will are highly connected with personal identity. External tools that may interfere with our decisions can call into question, or even challenge, an individual’s free will, and consequently, an individual’s responsibilities.  In this way, neurotechnology could affect freedom of thought, decision-making and action. Taken altogether this could deeply impact justice systems and social organizations.
d)	Mental privacy and brain data confidentiality. There are specific issues that can arise from brain data collected by neurotechnology. Mental activity is the most intimate part of the human being, and should be protected against illegitimate interference. Neurotechnologies can acquire a lot of data from users and these data need to be protected. Some aspects of these data are already subject to regulations: health data and personal data at least in jurisdictions that have adopted laws such as the GDPR. So as illustrated by the following: 
i) Specificity of brain data arise from the inference that can be made from their analysis to actual awareness, emotional state or even thoughts. It is thus essential to preserve the inviolability of the confidentiality of this particular kind of brain data. Thus, mental privacy must be protected. 
ii) The inference that can be made from brain data analysis may also enable prediction of an individual’s behaviour. Big data analytics enable privacy-sensitive inferences to be made from non-sensitive data. Here we have identified the risk of neurosurveillance, monitoring, for example, attentional engagement or awareness at the workplace or at school. Thus, brain data confidentiality must be protected. Brain data should be considered as sensitive personal data.
e)	Distributive justice. Neurotechnology can bring benefits for humans, particularly for neurological and mental health, but also in several other fields such as education. However, their availability and accessibility may present a problem if they bring an increase in the inequalities by giving privileges to a few who may have access and the exclusion of those who do not have access due to economic, social, cultural, moral, religious or geographic reasons. It is thus necessary to ensure well-regulated and fair access of these technologies.
f)	Discrimination/Bias. The algorithms driving most contemporary neurotechnologies, working according to an average or standard, classify the individuals from whom the data are being collected into groups, thereby reinforcing prejudices and biases that may result in discrimination and enhance vulnerability of individuals and groups. It is necessary, then, to detect bias and prejudice in classification algorithms and devise ways to remove them, before introducing AI implements and neurotechnologies to the population more broadly. 
g)	Misuse. This issue concerns unauthorized or coercive use of neurotechnology, such as a breach in cybersecurity if access to neural data has been fraudulent. Third-party interference in device function for non-benign purposes or malicious hacking also exist as serious concerns.
h)	Augmentation/enhancement. Some neurotechnologies are being developed with the purpose of enhancing cognitive capabilities. There are serious ethical questions regarding how this kind of “enhancing neurotechnology” can be used appropriately, given the lack of safety and efficacy, and the challenges related to human dignity, autonomy and justice.
i)	Interest of the child. It is necessary to pay special attention to the way the use of neurotechnologies could affect the brain in childhood and adolescence. At this rapidly changing and life-defining period of development of the brain, it is crucial to preserve the future rights of children and adolescents to make autonomous decisions and their privacy. Special considerations and specific guidelines and regulations must be implemented when neurodevices are used in healthcare for children and adolescents or by them for personal use such as neurogaming or neuroeducation.
j)	Informed consent: Considering the potential of changes in perception of personal identity and cognitive abilities, additional safeguards and robust and context specific informed consent procedures must be followed in view of the nature of the technology.
184.	Considering these challenges, several options were discussed by the IBC to recognize and protect neuro-rights:
a)	add protocols to international treaties, such as the Universal Declaration on Human Rights, to address challenges posed by neurotechnologies;
b)	reinforce the Universal Declaration on Human Rights, considering that neurotechnology challenges existing human rights and new guarantees will be required based on the potential for infringements;
c)	elaborate a New Universal Declaration on Human Rights and Neurotechnology.
185.	The IBC considers that neuro-rights embrace certain human rights that are already recognized in national laws, international laws and international human rights instruments and other consensus documents. These rights rest on the recognition of the basic rights of all individuals to physical and mental integrity, mental privacy, freedom of thought and free will, and the right to enjoy the benefits of scientific progress, and on the recognition of the need to protect and promote these rights with regard to the application of neurotechnology. It also includes the right to decide freely and responsibly on matters related to the use of neurotechnology, without any form of discrimination, coercion and violence.
Recommendations of the IBC to UNESCO 
186.	This report reveals the multidimensional impact of the rapid advancements in neurotechnology, shedding light on both positive and negative aspects. Based on the analysis provided in the report, UNESCO should pursue actions towards the implementation of its recommendations. To this end, IBC calls on UNESCO to use its unique global mandate in the ethics of science and technology, and its multifaceted expertise, to address the challenges highlighted by this report: 
a)	to provide new insights on the interpretations and applications of existing human rights instruments by legislative bodies and courts regarding the new challenges;
b)	to propose the adaptation of existing human rights instruments and the proclamation of new human rights; and
c)	to organize global dialogues in the field of human rights towards building a consensus on the nature and substance of neuro-rights. 
187.	In order to keep pace with the fast-advancing technologies, particularly in terms of regulating their application in the wide range of domains, UNESCO can convene a multidisciplinary group of experts to develop a policy-oriented governance model, to monitor the progress in the field, and to see if the issues raised are effectively covered by the existing legal frameworks. This governance model would build on the existing human rights architecture and incorporate the relevant principles identified in this report, paving the way towards the eventual elaboration of a new normative instrument on neuro-rights. 
188.	The IBC emphasizes that the following considerations are essential for the elaboration of such an international instrument:
a)	all humans have a right to protection of their brain activities regardless of race, gender and socio-economic status and cognitive abilities;
b)	brain data obtained from neurotechnology should not be used for surveillance or profiling without proper informed consent, and never for potential discrimination based on cognitive or other mental features;
c)	uses of neurotechnology by state and non-state actors should be scrutinized for possible violations of human rights;
d)	promoting dissemination of information, education and dialogue on neurotechnology is of paramount importance to ensure responsible and ethical use.
189.	UNESCO should lead efforts in cooperation with the other relevant international organizations. UNESCO may consider establishing a global virtual forum to share best practices and innovative ideas to maximize the benefits while minimizing the risks associated with the use of this technology.
Recommendations of the IBC to Member States
190.	On the basis of constitutionally recognized human rights, IBC encourages Member States to guarantee neuro-rights. Granting neuro-rights a positive status will empower citizens to claim respect to these rights as well as empower member states to provide appropriate legal frameworks for the production and use of neurotechnology. 
191.	Consequently, the IBC calls Members States to:
a)	Ensure that their fundamental laws clearly recognize and guarantee that the physical and mental integrity allows people to fully enjoy their personal identity, and the right to act in a self-determined manner and that only the law may establish the requirements to limit this right.
b)	Adopt laws to regulate the use of neurotechnology, such as recording of brain activities, especially when their purpose in not for scientific research, medical needs or administration of justice.
c)	Promote education, engagement and empowerment on emerging technologies and particularly on neurotechnology. Recognize that public education, engagement and empowerment (EEE) is critical for optimal decision-making and societal acceptance of neurotechnology.
d)	Protect the rights of individuals and the members of a group or institution such as schools, companies or any other to refuse the use of neurotechnology and therefore not be excluded or devalued. Alternatives should be sought for them. Nobody should be forced to accept neurotechnology that may alter their sense of self or personal identity as well as their capacities of self-determination.
e)	Protect the rights to have access to alternatives that are not neurotechnology-based and that offer the same effectiveness.
f)	Protect the right not to be socially bombarded by neurotechnology marketing in order to promote a supposed human improvement.
g)	Address the need to increase the traceability and auditability of data-driven inferences, due to the current poor regulation of direct-to-consumer neurotechnology. 
h)	Address the need to increase oversight of easy-to-co-opt unsupervised neurotechnology applications. 
i)	For the same reason (current poor regulation) and often deficient information, address the need to inform the consumer of neurotechnology about the possible risks to directly and/or indirectly influence in one’s privacy; the possibilities and risks of data sharing (when applicable); the risks of non-therapeutic enhancement as well as information about what is neuromarketing and its risks. Ensure that pertinent information emanating from neurotechnology developments/research must be timely publicized in a clear and culturally-appropriate language. Unfair or deceptive business practices should be prohibited.
j)	Help facilitate broad and inclusive discussions on the topic of neurotechnology at the local, national, and global levels. 
k)	Develop equitable access to neurotechnology, not only in the medical field but also in the areas of education and other fields of human development.
l)	Member States should consider laws or other mechanisms to regulate the use of paediatric neuro-enhancement tools in children. Neurotechnology should be carefully studied and assessed for its safety and efficacy before its use on children.

Recommendations of the IBC to the research community
192.	IBC recognizes the tremendous benefits that may arise from the development of neurotechnology to understand how our brain works at an individual as well as at a collective level, and to alleviate the heavy burden of neurological and mental disorders. IBC thus strongly supports a responsible development of research on neurotechnology. Consequently, IBC calls the research community:
a)	To develop a Code of Conduct for responsible research and innovation in neurotechnology. Such a code should be neuro-rights-based within the context of multidisciplinary integration of research teams, involving experts from law/ethics, natural sciences, engineering, neuroscience and civil society representatives. Evaluations could only be made efficiently once each protocol and procedure are carefully defined, according to a validated selection of the evaluation instruments and the inclusion and exclusion criteria.
b)	To address the specific challenge that may arise on informed consent and protection of privacy issues (for example preventing re-identification based on facial recognition from brain scan images or default mode analysis of the brain activity). These challenges include ways to strengthen informed consent where prospective research participants have cognitive impairment/disturbance or where the neuro-technologies may interfere with the individual’s  capacity to give further informed consent to continue the research.  Research participants should be fully informed of the possibility of an intervention affecting their sense of self, personal identity, or self-determination.
c)	Research in neurotechnology should be encouraged to adhere to the principles championed by the “Open Science” movement, in order to ensure experimental rigor and data reproducibility of research approaches, thus accelerating discoveries and the development of beneficial therapeutic interventions and devices. Considering the potential re-use of the data and their availability to a large community, researchers should also establish clear confidentiality and privacy policies. In the information provided to the participants of the research during the informed consent process, the possibility that their data can be shared in scientific exchanges should be explained, keeping due privacy and individual anonymity.
d)	To raise awareness of researchers about dual-use. We recommend that measures must be in place to protect against neurotechnologies being open to dual-use.
e)	Researchers should be encouraged to develop measures to counteract biases. This can include ensuring diversity in both the research team and the participants involved in research, as well as creating pluralistic focus groups for continuous feedback along the whole course of the technological development. For the sake of transparency, researchers and developers also must communicate biases to both the public and peers. Ensure that neurotechnology does not instil prejudices through algorithmic means.
f)	To introduce and promote responsible and accountable neurotechnology which has an emphasis on algorithmic transparency, security and privacy. Thus, its development and outcomes are respectful of human rights standards while at the same time promoting inclusion and the participation of diverse and representative human groups and experts. 
g)	To introduce and promote responsible and accountable neurotechnology which has an emphasis on its development according to human rights standards with the participation of diverse and representative human groups, taking into account privacy and security by design while being accountable for its outcomes while allowing proper auditing processes.
h)	To train and increase awareness and capacities of research ethics committees to assess and monitor neurotechnology research projects.
Recommendations of the IBC to the Industry 
193.	Since the industry is at the forefront of innovation in neurotechnology, a responsible innovation is required and IBC calls 
a)	Based on OECD recommendation 457 but not restricted to the health sector, a Code of Conduct for responsible research and innovation in neurotechnology is required to enhance security standards of neurodevices, algorithms and data-sharing infrastructures and develop a user-centred design.
b)	Algorithmic transparency to ensure that algorithms are fair and amenable to ex post and ex ante inspection, and avoid reinforce discrimination with gender, racial, sexual orientation or sexual identity bias.
c)	Data privacy transparency: measures must be taken to secure collected data, and determine its use or reuse. If AI is applied there must be guidelines on the purpose, the kind of analytics and the methods used to train systems and how decision-making processes are informed. One of the examples is imaging. Neuroimaging often needs careful anonymization, to make the face (profile) unrecognizable. 
d)	Data use should promote opt-out as the default mode.
e)	Data ownership transparency. Transparency should be ensured in using data generated from neurodevices to enable individuals to know if and how their data may be used or reused or transferred and to ensure data provenance. No brain data should be shared without due informed consent and an appropriate legal framework. 
f)	Avoid giving users false expectations and do not make unfair promises.
g)	Develop gender-neutral products ensuring inclusive approaches
Recommendations of the IBC to the Media
194.	Since the media, through its various channels, has the responsibility to raise the public awareness of new emerging technologies, it also has the responsibility to help the public understand neurotechnology, and report fairly on its benefits and its challenges. IBC calls:
a)	To inform the public on some misconceptions about neurotechnology associated with new emerging technologies by disseminating and verifying the accuracy of the scientific information given. Thus, the media can help the public in deciding what can and what should not be accepted. This will be especially beneficial in low-income countries where there is a high percentage of illiteracy, and the lack of access to Internet.
b)	To address the community in their appropriate language, thus helping them understand what they could not understand through other channels.
Recommendations of the IBC to the Public
195.	IBC calls to develop improved and more systematic national frameworks for facilitating meaningful Education, Engagement and Empowerment efforts related to neurotechnology and thus IBC call the public to;
a)	Reinforce that each individual is the owner of the data collected from him or her, and that it can only be used, published or traded only in exceptional circumstances and only with explicit informed consent.
b)	Become aware of potential benefits and risks in neurotechnology, especially where it impacts individual integrity, influences perception, or induces decision making, and engage in public debate and other actions to examine potential abuses.
c)	Become engaged in issues of neuroethics and neurorights, individually or through formation of interest groups.
d)	Use legal means, including laws and public pressure, to prevent potential abuse of neurotechnology by the government, public agencies or the private sector.

 
REPORT OF THE INTERNATIONAL BIOETHICS COMMITTEE OF UNESCO (IBC) 
ON THE ETHICAL ISSUES OF NEUROTECHNOLOGY
GLOSSARY
AFFECTIVE COMPUTING
Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affects. It is an interdisciplinary field spanning computer science, psychology, and cognitive science. 
ARTIFICIAL INTELLIGENCE (AI)
A collection of different technologies that seek to emulate and implement aspects or features of human (or natural) intelligence in machines. Current major subdivisions of AI are computer vision, language processing and robotics.
AUTHENTICITY
The degree to which a person’s actions are congruent with their values and desires. 
BIAS
A disproportionate weight in favour of or against an idea or thing, usually in a way that is closed-minded, prejudicial, or unfair. 
BRAIN
The central organ of the human nervous system (Ienca, 2021a).
BRAIN ACTIVITY 
The exchange of electrochemical signals between neurons (brain cells), which is commonly measured indirectly by different kinds of brain imaging (see below).
BRAIN FUNCTION
The function of neuronal circuits in the brain (Ienca, 2021a). 
BRAIN COMPUTER INTERFACE (BCI) (ALSO REFERRED TO AS BRAIN MACHINE INTERFACE)
A computer-based system that acquires brain signals, analyzes them, and translates them into commands that are relayed to an output device to carry out a desired action. In principle, any type of brain signal could be used to control a BCI system. (Shih et al, 2012)
BRAIN DATA (ALSO REFERRED TO AS NEURAL DATA)
Data that are recorded directly or indirectly from an individual’s brain, such as with brain imaging, intracranial recordings, or a brain computer interface
BRAIN DISORDERS
Psychological or neurological disorders that impair a person’s ability to function across cognitive, emotional, sensory and/or motor domains.
BRAIN IMAGING (also referred to as neuroimaging)
Techniques that employ an interaction between brain tissue and various forms of energy (eg, electromagnetic or particle radiation), rather than physical incision, to capture positional data about the structure and function of the brain.  Types of brain imaging mentioned in this report include computerised tomography scanning, (functional) magnetic resonance imaging, electroencephalography, magnetoencephalography, cranial ultrasound, positron emission tomography and functional near-infrared spectroscopy
BRAIN STIMULATION (also referred to as neurostimulation)
Activating or inhibiting the brain directly with electricity. Electricity can be applied directly by electrodes implanted in the brain, or noninvasively through electrodes placed on the scalp. The electricity can also be induced by using magnetic fields applied to the head.  
COMPUTATIONAL NEUROSCIENCE
Field of study in which mathematical tools and theories are used to investigate brain function. It can also incorporate diverse approaches from electrical engineering, computer science and physics in order to understand how the nervous system processes information. 
CONSCIOUSNESS
The state of being aware of and responsive to one’s surroundings. 
DEEP BRAIN STIMULATION
An invasive surgical procedure in which electrodes are implanted into certain brain areas. These electrodes, or leads, generate electrical impulses that control abnormal brain activity. The electrical impulses can also adjust for the chemical imbalances within the brain that cause various conditions. Stimulation of brain areas is controlled by a programmable generator that is placed under the skin in the upper chest. 
DIGITAL EXHAUST
All the information or ‘consumer’ data a person creates as they interact with websites and services. Digital exhaust contains highly sensitive personal information that can identify individuals and reveal their private activities. 
DIGITAL PHENOTYPING 
The moment-by-moment quantification of the individual-level human phenotype in situ using data from personal digital devices (Torous et al, 2016). The data that build a person’s digital phenotype can be divided into two subgroups: active data and passive data, where the former refers to data that requires active input from the users to be generated, whereas passive data, such as sensor data and phone usage patterns, are collected without requiring any active participation from the user. 
DIGNITY 
The state or quality of being worthy of honour or respect. 
DISCRIMINATION 
The unjust or prejudicial treatment of different categories of people, especially on the grounds of race, age, sex, or disability – or in the context of neurotechnology, brain function. 
DIRECT-TO-CONSUMER (DTC) (also referred to as business-to-consumer, or BTC)
When companies sell products directly to consumers, bypassing third-party retailers, wholesalers, or other middlemen. 
EQUITY
Providing people with what they need, in order to make things fair. Unlike equality, equity means giving more to those who need it, proportionate to their circumstances, to ensure that everyone has the same opportunities.  
EXISTENTIALISM
A form of philosophical inquiry that explores the problem of human existence and centres on the experiences of thinking, feeling and acting.  
MENTAL ILLNESS (also referred to as psychiatric disorders) 
A general term that refers to a group of illnesses, in the same way that heart disease refers to a group of illnesses and disorders affecting the heart. A mental illness is a health problem that significantly affects how a person feels, thinks, behaves, and interacts with other people. 
MENTAL INTEGRITY 
Mental Integrity is the individual's mastery of his mental states and his brain data so that, without his consent, no one can read, spread, or alter such states and data in order to condition the individual in any way. (Lavazza, 2018, ref 26).
MENTAL PRIVACY 
A right to explicitly protects individuals against the unconsented intrusion by third parties into their mental information (be it inferred from their neural data or from proxy data indicative of neurological, cognitive, and/or affective information) as well as against the unauthorized collection of those data. (Ienca and Andorno, 2017)
MONISM 
An approach to the mind-body problem that the mind and body are fundamentally one; in other words, there is only one unifying reality in substance or essence, in terms of which everything can be explained. 
NATURALISM ¬ 
The idea or belief that only natura laws and forces (as opposed to supernatural or spiritual ones) operate in the universe. All events, therefore, find their adequate explanation within nature itself.  
NEURODEVICES (also referred to as neurological devices) 
Devices that can be used to help restore hearing and sight or provide increased function for those with limb loss for congenital limb differences. Examples of neurodevices include neurodiagnostics, neurointerventional and neurostimulation devices. 
NEUROGAMING  
Emerging form of gaming where players interact with the game using a brain-computer interface (such as EEG), without the need for traditional controllers. 
NEUROMARKETING 
The measurement of physiological and neural signals to gain insight into customers’ motivations, preferences, and decisions, which can help inform creative advertising, product development, pricing, and other marketing areas. 
NEUROPROSTHETICS
Devices that can substitute for motor, sensory, or cognitive functions that have been impaired as a result of nervous system disorders (Kansaku, 2021). 
NEURORIGHTS
Ethical, legal, social or natural principles of freedom or entitlement related to a person’s cerebral and mental domain. (Ienca, 2021a) 
NEUROTECHNOLOGY 
The broad and heterogenous spectrum of methods, systems and instruments that establish a connection pathway to the human brain through which neural activity can be recorded and/or altered. (Ienca, 2021a) 
NOOTROPICS 
Types of drug often referred to as ‘cognitive enhancers’ that some people use in an attempt to improve memory, increase mental alertness and concentration as well as boost energy levels and wakefulness. Some nootropics are pharmaceutical drugs designed to treat conditions such as sleepiness or narcolepsy, and to improve attention and focus in people with attention disorders. However, some healthy people use these drugs in an attempt to improve their cognitive performance. 
ONTOLOGICAL 
Relating to the branch of metaphysics dealing with the nature of being. 
PRIVACY 
The ability of an individual or group to seclude themselves or information about themselves, and thereby express themselves selectively. When something is private to a person, it usually means that something is inherently special or sensitive to them.  
PSYCHOLOGICAL CONTINUITY
People’s continuity of their mental life over time (e.g., continuity across non-synchronous mental states) (Ienca, 2021a).
REDUCTIVISM (also known as reductionism) 
The practice of analysing and describing a complex phenomenon in terms of its simple or fundamental constituents, especially when this is said to provide a sufficient explanation.  

 
ANNEX 1
Description of a Brain Computer Interface (BCI), French National Academy of Medicine and Academy of Technologies, Joint report (Bioulac et al, 2020)

A BCI is most often a closed-loop system, including six main steps (Lotte, 2012):
 
Figure 1: Example of a brain-machine interface (Huggins et al, 2009)

1.	Collection and measurement of brain activity. The recording methods can be invasive or not. Invasive recordings use different types of electrode grids directly implanted in the cortical areas of interest (areas with motor, visual, auditory functions, etc.). The electrodes are in contact with the neurons and capture the action potentials they emit. Non-invasive recording methods, by their organization, underlie the codes forming the central messages (intention, ideas, etc.). Even if these methods operate as close as possible to the central signalling, they have many drawbacks: displacement and loss of neuronal contact, gliosis, infections.
Among the non-invasive methods, we should mention neuroimaging techniques (fMRI, MEG, fNIRS), but EEG remains the most widely used method; it measures, through electrodes, the micro-currents present on the surface of the scalp. The electrocorticogram (EcoG) is an EEG performed in direct contact with the cerebral cortex, it is partially invasive.
2.	Preprocessing. Spatial and temporal filters are used to eliminate parasitic muscular and ocular activities. 
3.	Extraction of features. This involves extracting from a large number of signals, characteristics (or patterns) concerning a given power in a frequency band. Thus, imagining a movement triggers activity in the motor areas, but the characteristics (or patterns) of the imaginary motor activity are of lower intensity than those of the real motor activity.
4.	Classification. This step consists in assigning, thanks to an algorithm and a threshold value, a class to the vector of features that represents the type of mental task performed by the user of the BCI.
5.	Translation into a command. The information is translated into a command according to the desired application. The command is given through a wired or wireless transceiver system.
6.	Perceptual feedback. This corresponds to the closing of the feedback loop allowing the subject to learn to control their brain activity; without this feedback they are not able to do so. This is the basis of the neurofeedback principle.
Asynchronous and synchronous BCI
In the use of an asynchronous BCI, the subject interacts with the system when they decide to do so by voluntarily modifying their brain activity (EEG). The control signals are continuous and allow a progressive control such as a cursor. Several signals are used: 
(1)	Slow Cortical Potential Shifts (SCPS). These are progressive variations of the average cortical potential (1 to 2 Hz for a few seconds), they are linked to mental states (availability...). Most subjects learn to control, by feedback, this potential and to provoke a positive or negative variation which is then transformed into a command by the ICM; 
(2)	Sensorimotor oscillatory activity. This is recorded in the area of the motor areas and is modified during motor activity and also when the subject imagines a movement. The energy of these signals is in the frequency bands (8-15 Hz) and (15-25 Hz). The subject learns, by feedback, to control the variations of these rhythms in the case of imagined movements in order to drive a MCI.
In a synchronous BCI, it is not the spontaneous activity of the brain that is recorded but instead, the brain’s response to a stimulus. The latter is detected in the EEG and transformed into a command. There are two main types of brain responses: 
(1)	Low-level visual evoked potentials (SSVERs: Steady State Visual Evoked Responses). They appear in the primary visual cortex after a visual stimulus. These potentials occur with an increase in the amplitude of the EEG signal in the frequency band corresponding to that of the stimulus. Subjects learn to control the amplitude of the SSVER through feedback and use it to interact with the BCI as in the game "Mind Shooter"; 
(2)	Event Related Potentials (ERPs). ERPs are EEG signals of short duration generated by a cerebral response to external stimuli (visual, auditory, tactile). One of the most commonly used ERPs is the P300 ERP which appears 300 ms after the stimulus and is related to a cognitive task. From then on, the detection of the P300 ERP is processed by the BCI to generate binary commands.
